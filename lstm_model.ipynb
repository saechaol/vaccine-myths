{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noah Venethongkham, 219660117\n",
    "# Ashley Thor, 219334909\n",
    "# Lucas Saechao, 218794239\n",
    "# CSC 180 - Intelligent Systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Noah\\anaconda3\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\Noah\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Noah\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Noah\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Noah\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Noah\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Noah\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Noah\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Noah\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Noah\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Noah\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Noah\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Noah\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Noah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# matplotlib\n",
    "%matplotlib inline\n",
    "from matplotlib.pyplot import figure, show\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# numpy and pandas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "\n",
    "# scikit learn\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, log_loss\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.utils import column_or_1d\n",
    "import sklearn.feature_extraction.text as sk_text\n",
    "import skimage.transform\n",
    "\n",
    "# natural language toolkit\n",
    "# run pip install nltk\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.test.utils import get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# tensorflow and keras\n",
    "from tensorflow.keras import optimizers, regularizers\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.layers import LSTM, Input, Dense, Activation, Flatten, Dropout, Conv1D, Conv2D, GlobalMaxPooling1D, MaxPooling1D, MaxPooling2D, Embedding\n",
    "#from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# run pip install np_utils\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# python libraries\n",
    "from collections.abc import Sequence\n",
    "import requests\n",
    "import pathlib\n",
    "import shutil\n",
    "import string\n",
    "import json\n",
    "import time\n",
    "import csv\n",
    "import io\n",
    "import os\n",
    "import re\n",
    "\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode text values to dummy variables(i.e. [1,0,0],[0,1,0],[0,0,1] for red,green,blue)\n",
    "def encode_text_dummy(df, name):\n",
    "    dummies = pd.get_dummies(df[name])\n",
    "    for x in dummies.columns:\n",
    "        dummy_name = \"{}-{}\".format(name, x)\n",
    "        df[dummy_name] = dummies[x]\n",
    "    df.drop(name, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# Encode text values to indexes(i.e. [1],[2],[3] for red,green,blue).\n",
    "def encode_text_index(df, name):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df[name] = le.fit_transform(df[name])\n",
    "    return le.classes_\n",
    "\n",
    "\n",
    "# Encode a numeric column as zscores\n",
    "def encode_numeric_zscore(df, name, mean=None, sd=None):\n",
    "    if mean is None:\n",
    "        mean = df[name].mean()\n",
    "    if sd is None:\n",
    "        sd = df[name].std()\n",
    "    df[name] = (df[name] - mean) / sd\n",
    "\n",
    "\n",
    "# Convert all missing values in the specified column to the median\n",
    "def missing_median(df, name):\n",
    "    med = df[name].median()\n",
    "    df[name] = df[name].fillna(med)\n",
    "\n",
    "\n",
    "# Convert all missing values in the specified column to the default\n",
    "def missing_default(df, name, default_value):\n",
    "    df[name] = df[name].fillna(default_value)\n",
    "\n",
    "\n",
    "# Convert a Pandas dataframe to the x,y inputs that TensorFlow needs\n",
    "def to_xy(df, target):\n",
    "    result = []\n",
    "    for x in df.columns:\n",
    "        if x != target:\n",
    "            result.append(x)\n",
    "    # find out the type of the target column. \n",
    "    target_type = df[target].dtypes\n",
    "    target_type = target_type[0] if isinstance(target_type, Sequence) else target_type\n",
    "    # Encode to int for classification, float otherwise. TensorFlow likes 32 bits.\n",
    "    if target_type in (np.int64, np.int32):\n",
    "        # Classification\n",
    "        dummies = pd.get_dummies(df[target])\n",
    "        return df[result].values.astype(np.float32), dummies.values.astype(np.float32)\n",
    "    else:\n",
    "        # Regression\n",
    "        return df[result].values.astype(np.float32), df[target].values.astype(np.float32)\n",
    "\n",
    "# Nicely formatted time string\n",
    "def hms_string(sec_elapsed):\n",
    "    h = int(sec_elapsed / (60 * 60))\n",
    "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
    "    s = sec_elapsed % 60\n",
    "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)\n",
    "\n",
    "\n",
    "# Regression chart.\n",
    "def chart_regression(pred,y,sort=True):\n",
    "    t = pd.DataFrame({'pred' : pred, 'y' : y.flatten()})\n",
    "    if sort:\n",
    "        t.sort_values(by=['y'],inplace=True)\n",
    "    a = plt.plot(t['y'].tolist(),label='expected')\n",
    "    b = plt.plot(t['pred'].tolist(),label='prediction')\n",
    "    plt.ylabel('output')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Remove all rows where the specified column is +/- sd standard deviations\n",
    "def remove_outliers(df, name, sd):\n",
    "    drop_rows = df.index[(np.abs(df[name] - df[name].mean()) >= (sd * df[name].std()))]\n",
    "    df.drop(drop_rows, axis=0, inplace=True)\n",
    "\n",
    "\n",
    "# Encode a column to a range between normalized_low and normalized_high.\n",
    "def encode_numeric_range(df, name, normalized_low=-1, normalized_high=1,\n",
    "                         data_low=None, data_high=None):\n",
    "    if data_low is None:\n",
    "        data_low = min(df[name])\n",
    "        data_high = max(df[name])\n",
    "    df[name] = ((df[name] - data_low) / (data_high - data_low)) \\\n",
    "               * (normalized_high - normalized_low) + normalized_low\n",
    "\n",
    "# Plots a confusion matrix for the model\n",
    "def plot_confusion_matrix(cm, names, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(names))\n",
    "    plt.xticks(tick_marks, names, rotation=45)\n",
    "    plt.yticks(tick_marks, names)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "# Plot an ROC curve\n",
    "def plot_roc(pred, y):\n",
    "    fpr, tpr, thresholds = roc_curve(y, pred)\n",
    "    roc_area_under_curve = auc(fpr, tpr)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label='ROC curve (area = $0.2f)' % roc_area_under_curve)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC)')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show\n",
    " \n",
    "def text_to_word_list(text):\n",
    "    text = str(text)\n",
    "    text = text.lower()\n",
    "    text = remove_stopwords(text)\n",
    "    \n",
    "    # clean text by regex\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    text = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'\\w+:\\/{2}[\\d\\w-]+(\\.[\\d\\w-]+)*(?:(?:\\/[^\\s/]*))*', '', text)\n",
    "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=><]\", \" \", text)\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"cannot \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\",\", \" \", text)\n",
    "    text = re.sub(r\"\\.\", \" \", text)\n",
    "    text = re.sub(r\"!\", \" ! \", text)\n",
    "    text = re.sub(r\"\\/\", \" \", text)\n",
    "    text = re.sub(r\"\\^\", \" ^ \", text)\n",
    "    text = re.sub(r\"\\+\", \" + \", text)\n",
    "    text = re.sub(r\"\\>\", \" \", text)\n",
    "    text = re.sub(r\"\\-\", \" - \", text)\n",
    "    text = re.sub(r\"\\=\", \" = \", text)\n",
    "    text = re.sub(r\"\\'\", \" \", text)\n",
    "    text = re.sub(r\"'\", \" \", text)\n",
    "    text = re.sub(r\"(\\d+)(k)\", \"\\g<1>000\", text)\n",
    "    text = re.sub(r\":\", \" : \", text)\n",
    "    text = re.sub(r\" e g \", \" eg \", text)\n",
    "    text = re.sub(r\" b g \", \" bg \", text)\n",
    "    text = re.sub(r\" u s \", \" american \", text)\n",
    "    text = re.sub(r\"\\0s\", \"0\", text)\n",
    "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
    "    text = re.sub(r\"e - mail\", \"email\", text)\n",
    "    text = re.sub(r\"covid19\", \"covid\", text)\n",
    "    text = re.sub(r\"j k\", \"jk\", text)\n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "    text = re.sub('_', ' ', text)\n",
    "    return text\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    stopwords_list = stopwords.words('english')\n",
    "    whitelist = [\"n't\", \"not\", \"no\"]\n",
    "    words = text.split()\n",
    "    words_clean = [word for word in words if (word not in stopwords_list or word in whitelist) and len(word) > 1]\n",
    "    return \" \".join(words_clean)\n",
    "    \n",
    "def remove_stop_manual(data):\n",
    "    stopwords = [ \"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"as\", \"at\", \"be\", \"because\", \n",
    "             \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"could\", \"did\", \"do\", \"does\", \"doing\", \"down\", \"during\",\n",
    "             \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"has\", \"have\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\", \n",
    "             \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\",\n",
    "             \"is\", \"it\", \"it's\", \"its\", \"itself\", \"let's\", \"me\", \"more\", \"most\", \"my\", \"myself\", \"nor\", \"of\", \"on\", \"once\", \"only\", \"or\",\n",
    "             \"other\", \"ought\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"she\", \"she'd\", \"she'll\", \"she's\", \"should\", \n",
    "             \"so\", \"some\", \"such\", \"than\", \"that\", \"that's\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"there's\",\n",
    "             \"these\", \"they\", \"they'd\", \"they'll\", \"they're\", \"they've\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\",\n",
    "             \"very\", \"was\", \"we\", \"we'd\", \"we'll\", \"we're\", \"we've\", \"were\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\",\n",
    "             \"which\", \"while\", \"who\", \"who's\", \"whom\", \"why\", \"why's\", \"with\", \"would\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\",\n",
    "             \"your\", \"yours\", \"yourself\", \"yourselves\" ]\n",
    "    data = data.apply(lambda x : ' '.join([word for word in x.split() if word not in (stopwords)]))\n",
    "    return data\n",
    "    \n",
    "def read_glove_vector(glove_vec):\n",
    "    with open(glove_vec, 'r', encoding='utf-8') as f:\n",
    "        words = set()\n",
    "        word_to_vec_map = {}\n",
    "        for line in f:\n",
    "            w_line = line.split()\n",
    "            current_word = w_line[0]\n",
    "            word_to_vec_map[current_word] = np.array(w_line[1:], dtype=np.float64)\n",
    "    return word_to_vec_map\n",
    "    \n",
    "def lstm_model(input_shape):\n",
    "    x_indices = Input(input_shape)\n",
    "    embeddings = embedding_layer(x_indices)\n",
    "    x = LSTM(128, return_sequences=True)(embeddings)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = LSTM(128, return_sequences=True)(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = LSTM(128)(x)\n",
    "    x = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=x_indices, outputs=x)\n",
    "    return model\n",
    "\n",
    "def conv_model(input_shape):\n",
    "    x_indices = Input(input_shape)\n",
    "    embeddings = embedding_layer(x_indices)\n",
    "    x = Conv1D(512, 3, activation='relu')(embeddings)\n",
    "    x = MaxPooling1D(3)(x)\n",
    "    x = Conv1D(256, 3, activation='relu')(x)\n",
    "    x = MaxPooling1D(3)(x)\n",
    "    x = Conv1D(256, 3, activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = MaxPooling1D(3)(x)\n",
    "    x = GlobalMaxPooling1D()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=x_indices, outputs=x)\n",
    "    return model\n",
    "    \n",
    "def predict_sentiments(data, corpus):\n",
    "    data['sentiment score'] = 0\n",
    "    corpus = pad_sequences(corpus, maxlen=max_len, padding='post')\n",
    "    pred = convolution_model.predict(corpus)\n",
    "    data['sentiment score'] = pred\n",
    "    pred_sentiment = np.array(list(map(lambda x: 'positive' if x > 0.5 else 'negative', pred)))\n",
    "    data['predicted sentiment'] = 0\n",
    "    data['predicted sentiment'] = pred_sentiment\n",
    "    return data\n",
    "\n",
    "def predict_sentiments_lstm(data, corpus):\n",
    "    data['sentiment score'] = 0\n",
    "    corpus = pad_sequences(corpus, maxlen=max_len, padding='post')\n",
    "    pred = lstm_model.predict(corpus)\n",
    "    data['sentiment score'] = pred\n",
    "    pred_sentiment = np.array(list(map(lambda x: 'positive' if x > 0.5 else 'negative', pred)))\n",
    "    data['predicted sentiment'] = 0\n",
    "    data['predicted sentiment'] = pred_sentiment\n",
    "    return data\n",
    "    \n",
    "# Beep if on a windows machine\n",
    "if os.name == 'nt':\n",
    "    def ding():\n",
    "        winsound.Beep(2000, 300)\n",
    "        winsound.Beep(2000, 300)\n",
    "        winsound.Beep(2000, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  title  \\\n",
      "0     Health Canada approves AstraZeneca COVID-19 va...   \n",
      "1     COVID-19 in Canada: 'Vaccination passports' a ...   \n",
      "2     Coronavirus variants could fuel Canada's third...   \n",
      "3     Canadian government to extend COVID-19 emergen...   \n",
      "4     Canada: Pfizer is 'extremely committed' to mee...   \n",
      "...                                                 ...   \n",
      "1486                                                      \n",
      "1487                                                      \n",
      "1488                                                      \n",
      "1489                                                      \n",
      "1490                                                      \n",
      "\n",
      "                                                   body sentiment  \n",
      "0                                                        positive  \n",
      "1                                                                  \n",
      "2                                                                  \n",
      "3                                                                  \n",
      "4                                                        positive  \n",
      "...                                                 ...       ...  \n",
      "1486  The problem is the calculations themselves and...  positive  \n",
      "1487  I created the Vaxfact site using references to...            \n",
      "1488  >The information I provided is not wrong\\r\\n\\r...  positive  \n",
      "1489  Basically nothing.\\r\\n\\r\\n>Autoimmunity to the...  positive  \n",
      "1490  In this instance, yourself. Broader, that Vaxf...            \n",
      "\n",
      "[1491 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create pandas dataframe output file\n",
    "df_reddit = pd.read_csv('reddit_vm.csv', encoding=\"utf-8\")\n",
    "df_reddit = df_reddit[['title', 'body', 'sentiment']].fillna('')\n",
    "df_reddit['title'] = df_reddit['title'].replace(to_replace='Comment', value='')\n",
    "\n",
    "print(df_reddit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  title  \\\n",
      "0     Health Canada approves AstraZeneca COVID-19 va...   \n",
      "1     COVID-19 Canada: 'Vaccination passports' near ...   \n",
      "2         Coronavirus variants fuel Canada's third wave   \n",
      "3     Canadian government extend COVID-19 emergency ...   \n",
      "4     Canada: Pfizer 'extremely committed' meeting v...   \n",
      "...                                                 ...   \n",
      "1486                                                      \n",
      "1487                                                      \n",
      "1488                                                      \n",
      "1489                                                      \n",
      "1490                                                      \n",
      "\n",
      "                                                   body sentiment  \n",
      "0                                                        positive  \n",
      "1                                                                  \n",
      "2                                                                  \n",
      "3                                                                  \n",
      "4                                                        positive  \n",
      "...                                                 ...       ...  \n",
      "1486  The problem calculations idea layperson napkin...  positive  \n",
      "1487  created Vaxfact site using references reliable...            \n",
      "1488  >The information provided not wrong You've rep...  positive  \n",
      "1489  Basically nothing. >Autoimmunity central nervo...  positive  \n",
      "1490      In instance, yourself. Broader, Vaxfact site.            \n",
      "\n",
      "[1491 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "df_reddit.body = remove_stop_manual(df_reddit.body)\n",
    "df_reddit.title = remove_stop_manual(df_reddit.title)\n",
    "\n",
    "df_reddit.body = df_reddit.body.apply(remove_stopwords)\n",
    "df_reddit.title = df_reddit.title.apply(remove_stopwords)\n",
    "print(df_reddit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       positive\n",
       "1       negative\n",
       "2       negative\n",
       "3       negative\n",
       "4       positive\n",
       "          ...   \n",
       "1486    positive\n",
       "1487    negative\n",
       "1488    positive\n",
       "1489    positive\n",
       "1490    negative\n",
       "Name: sentiment, Length: 1491, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sentiment = df_reddit.sentiment\n",
    "df_sentiment.replace('', 'negative', inplace=True)\n",
    "df_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_title = df_reddit.title\n",
    "df_title.replace('', np.nan, inplace=True)\n",
    "df_title.to_frame(name=\"text\")\n",
    "df_body = df_reddit.body\n",
    "df_body.to_frame(name=\"text\")\n",
    "df_body.replace('', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Health Canada approves AstraZeneca COVID-19 va...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COVID-19 Canada: 'Vaccination passports' near ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Coronavirus variants fuel Canada's third wave</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Canadian government extend COVID-19 emergency ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Canada: Pfizer 'extremely committed' meeting v...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1486</th>\n",
       "      <td>NaN</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1487</th>\n",
       "      <td>NaN</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1488</th>\n",
       "      <td>NaN</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1489</th>\n",
       "      <td>NaN</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1490</th>\n",
       "      <td>NaN</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1491 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title sentiment\n",
       "0     Health Canada approves AstraZeneca COVID-19 va...  positive\n",
       "1     COVID-19 Canada: 'Vaccination passports' near ...  negative\n",
       "2         Coronavirus variants fuel Canada's third wave  negative\n",
       "3     Canadian government extend COVID-19 emergency ...  negative\n",
       "4     Canada: Pfizer 'extremely committed' meeting v...  positive\n",
       "...                                                 ...       ...\n",
       "1486                                                NaN  positive\n",
       "1487                                                NaN  negative\n",
       "1488                                                NaN  positive\n",
       "1489                                                NaN  positive\n",
       "1490                                                NaN  negative\n",
       "\n",
       "[1491 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_title_sentiment = pd.concat([df_title, df_sentiment], axis=1)\n",
    "df_title_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1486</th>\n",
       "      <td>The problem calculations idea layperson napkin...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1487</th>\n",
       "      <td>created Vaxfact site using references reliable...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1488</th>\n",
       "      <td>&gt;The information provided not wrong You've rep...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1489</th>\n",
       "      <td>Basically nothing. &gt;Autoimmunity central nervo...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1490</th>\n",
       "      <td>In instance, yourself. Broader, Vaxfact site.</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1491 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   body sentiment\n",
       "0                                                   NaN  positive\n",
       "1                                                   NaN  negative\n",
       "2                                                   NaN  negative\n",
       "3                                                   NaN  negative\n",
       "4                                                   NaN  positive\n",
       "...                                                 ...       ...\n",
       "1486  The problem calculations idea layperson napkin...  positive\n",
       "1487  created Vaxfact site using references reliable...  negative\n",
       "1488  >The information provided not wrong You've rep...  positive\n",
       "1489  Basically nothing. >Autoimmunity central nervo...  positive\n",
       "1490      In instance, yourself. Broader, Vaxfact site.  negative\n",
       "\n",
       "[1491 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_body_sentiment = pd.concat([df_body, df_sentiment], axis=1)\n",
    "df_body_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Health Canada approves AstraZeneca COVID-19 va...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COVID-19 Canada: 'Vaccination passports' near ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Coronavirus variants fuel Canada's third wave</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Canadian government extend COVID-19 emergency ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Canada: Pfizer 'extremely committed' meeting v...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>father five unvaccinated children. Am unfit pa...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>Love Them. Protect Them. Never Inject Them.</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>Vaccines Are Just Asping For Trouble</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>Dr. Harper explained presentation cervical can...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>Polio arose US period pesticide use skyrockete...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>450 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title sentiment\n",
       "0    Health Canada approves AstraZeneca COVID-19 va...  positive\n",
       "1    COVID-19 Canada: 'Vaccination passports' near ...  negative\n",
       "2        Coronavirus variants fuel Canada's third wave  negative\n",
       "3    Canadian government extend COVID-19 emergency ...  negative\n",
       "4    Canada: Pfizer 'extremely committed' meeting v...  positive\n",
       "..                                                 ...       ...\n",
       "445  father five unvaccinated children. Am unfit pa...  negative\n",
       "446        Love Them. Protect Them. Never Inject Them.  negative\n",
       "447               Vaccines Are Just Asping For Trouble  negative\n",
       "448  Dr. Harper explained presentation cervical can...  negative\n",
       "449  Polio arose US period pesticide use skyrockete...  negative\n",
       "\n",
       "[450 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_title_clean = df_title_sentiment.dropna().drop_duplicates().reset_index(drop=True)\n",
    "df_title_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Your OP. It's not myth. Only one vaccine conta...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://youtu.be/zBkVCpbNnkU</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Because Anti-Vaxxers no sense</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What mean \"your OP\". fairly new reddit.</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>When say no thimerasol, mean childhood schedul...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1093</th>\n",
       "      <td>The problem calculations idea layperson napkin...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1094</th>\n",
       "      <td>created Vaxfact site using references reliable...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>&gt;The information provided not wrong You've rep...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096</th>\n",
       "      <td>Basically nothing. &gt;Autoimmunity central nervo...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1097</th>\n",
       "      <td>In instance, yourself. Broader, Vaxfact site.</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1098 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   body sentiment\n",
       "0     Your OP. It's not myth. Only one vaccine conta...  negative\n",
       "1                          https://youtu.be/zBkVCpbNnkU  positive\n",
       "2                         Because Anti-Vaxxers no sense  positive\n",
       "3               What mean \"your OP\". fairly new reddit.  negative\n",
       "4     When say no thimerasol, mean childhood schedul...  negative\n",
       "...                                                 ...       ...\n",
       "1093  The problem calculations idea layperson napkin...  positive\n",
       "1094  created Vaxfact site using references reliable...  negative\n",
       "1095  >The information provided not wrong You've rep...  positive\n",
       "1096  Basically nothing. >Autoimmunity central nervo...  positive\n",
       "1097      In instance, yourself. Broader, Vaxfact site.  negative\n",
       "\n",
       "[1098 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_body_clean = df_body_sentiment.dropna().drop_duplicates().reset_index(drop=True)\n",
    "df_body_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corpus = pd.DataFrame(index=range(0, 1524), columns=['text', 'sentiment'], dtype='object')\n",
    "df_corpus_text = pd.concat([df_title_clean.title, df_body_clean.body])\n",
    "df_corpus_sentiment = pd.concat([df_title_clean.sentiment, df_body_clean.sentiment])\n",
    "df_corpus_text = df_corpus_text.to_frame(name='text')\n",
    "df_corpus_text.reset_index(inplace=True)\n",
    "df_corpus_sentiment = df_corpus_sentiment.to_frame(name='sentiment')\n",
    "df_corpus_sentiment.reset_index(inplace=True)\n",
    "df_corpus.text = df_corpus_text.text\n",
    "df_corpus.sentiment = df_corpus_sentiment.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Health Canada approves AstraZeneca COVID-19 va...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COVID-19 Canada: 'Vaccination passports' near ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Coronavirus variants fuel Canada's third wave</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Canadian government extend COVID-19 emergency ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Canada: Pfizer 'extremely committed' meeting v...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment\n",
       "0  Health Canada approves AstraZeneca COVID-19 va...  positive\n",
       "1  COVID-19 Canada: 'Vaccination passports' near ...  negative\n",
       "2      Coronavirus variants fuel Canada's third wave  negative\n",
       "3  Canadian government extend COVID-19 emergency ...  negative\n",
       "4  Canada: Pfizer 'extremely committed' meeting v...  positive"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corpus.text = df_corpus.text.apply(lambda x: text_to_word_list(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df_corpus.text\n",
    "sentiments = df_corpus.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_list = []\n",
    "for i in range(len(texts)):\n",
    "    corpus_list.append(texts[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert sentiment from string to data in the binary form of 1 to 0\n",
    "y = np.array(list(map(lambda x: 1 if x==\"positive\" else 0, sentiments)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 0, 1, 0])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(corpus_list, y, test_size=0.3, random_state=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1066\n",
      "458\n",
      "1066\n",
      "458\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train))\n",
    "print(len(x_test))\n",
    "print(len(y_train))\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=25000)\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "word_to_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_file_loc = os.path.join(\n",
    "    os.path.expanduser('~'), '.keras/datasets/glove.6B.300d.txt'\n",
    ")\n",
    "word_to_vec_map = read_glove_vector(glove_file_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6307\n",
      "300\n",
      "(6308, 300)\n"
     ]
    }
   ],
   "source": [
    "vocab_len = len(word_to_index)\n",
    "embed_vector_len = word_to_vec_map['moon'].shape[0]\n",
    "emb_matrix = np.zeros((vocab_len + 1, embed_vector_len))\n",
    "print(vocab_len)\n",
    "print(embed_vector_len)\n",
    "print(emb_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word, index in word_to_index.items():\n",
    "    embedding_vec = word_to_vec_map.get(word)\n",
    "    if embedding_vec is not None:\n",
    "        emb_matrix[index, :] = embedding_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Noah\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = Embedding(\n",
    "    input_dim=vocab_len + 1,\n",
    "    output_dim=embed_vector_len,\n",
    "    input_length=max_len,\n",
    "    weights=[emb_matrix],\n",
    "    trainable=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Noah\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 150)]             0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 150, 300)          1892400   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 150, 128)          219648    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 150, 128)          0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 150, 128)          131584    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 150, 128)          0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 2,375,345\n",
      "Trainable params: 482,945\n",
      "Non-trainable params: 1,892,400\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = lstm_model((max_len,))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 150)]             0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 150, 300)          1892400   \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 148, 512)          461312    \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 49, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 47, 256)           393472    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 15, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 13, 256)           196864    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 13, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 4, 256)            0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 3,010,097\n",
      "Trainable params: 1,117,697\n",
      "Non-trainable params: 1,892,400\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "convolution_model = conv_model((max_len,))\n",
    "convolution_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_indices = tokenizer.texts_to_sequences(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1066, 150)\n"
     ]
    }
   ],
   "source": [
    "x_train_indices = pad_sequences(x_train_indices, maxlen=max_len, padding='post')\n",
    "print(x_train_indices.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_indices = tokenizer.texts_to_sequences(x_test)\n",
    "x_test_indices = pad_sequences(x_test_indices, maxlen=max_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Noah\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "adam = tf.keras.optimizers.Adam(learning_rate = 0.0001)\n",
    "convolution_model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-6, patience=10, verbose=2, mode='auto')\n",
    "checkpoint = ModelCheckpoint(filepath=\"best_weights_conv1d.hdf5\", verbose=0, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1066 samples, validate on 458 samples\n",
      "Epoch 1/15\n",
      "1066/1066 [==============================] - 8s 7ms/sample - loss: 0.5476 - acc: 0.8377 - val_loss: 0.5072 - val_acc: 0.8231\n",
      "Epoch 2/15\n",
      "1066/1066 [==============================] - 0s 355us/sample - loss: 0.4786 - acc: 0.8293 - val_loss: 0.4896 - val_acc: 0.8231\n",
      "Epoch 3/15\n",
      "1066/1066 [==============================] - 0s 293us/sample - loss: 0.4474 - acc: 0.8377 - val_loss: 0.4865 - val_acc: 0.8231\n",
      "Epoch 4/15\n",
      "1066/1066 [==============================] - 0s 269us/sample - loss: 0.4139 - acc: 0.8377 - val_loss: 0.4762 - val_acc: 0.8231\n",
      "Epoch 5/15\n",
      "1066/1066 [==============================] - 0s 207us/sample - loss: 0.3844 - acc: 0.8386 - val_loss: 0.4705 - val_acc: 0.8231\n",
      "Epoch 6/15\n",
      "1066/1066 [==============================] - 0s 164us/sample - loss: 0.3615 - acc: 0.8518 - val_loss: 0.4978 - val_acc: 0.7860\n",
      "Epoch 7/15\n",
      "1066/1066 [==============================] - 0s 160us/sample - loss: 0.3190 - acc: 0.8762 - val_loss: 0.4729 - val_acc: 0.8079\n",
      "Epoch 8/15\n",
      "1066/1066 [==============================] - 0s 210us/sample - loss: 0.2721 - acc: 0.8921 - val_loss: 0.4692 - val_acc: 0.7969\n",
      "Epoch 9/15\n",
      "1066/1066 [==============================] - 0s 214us/sample - loss: 0.2290 - acc: 0.9137 - val_loss: 0.4616 - val_acc: 0.8122\n",
      "Epoch 10/15\n",
      "1066/1066 [==============================] - 0s 216us/sample - loss: 0.1741 - acc: 0.9371 - val_loss: 0.4572 - val_acc: 0.8166\n",
      "Epoch 11/15\n",
      "1066/1066 [==============================] - 0s 162us/sample - loss: 0.1274 - acc: 0.9681 - val_loss: 0.4651 - val_acc: 0.7838\n",
      "Epoch 12/15\n",
      "1066/1066 [==============================] - 0s 162us/sample - loss: 0.0928 - acc: 0.9775 - val_loss: 0.4665 - val_acc: 0.8144\n",
      "Epoch 13/15\n",
      "1066/1066 [==============================] - 0s 162us/sample - loss: 0.0648 - acc: 0.9887 - val_loss: 0.5062 - val_acc: 0.7838\n",
      "Epoch 14/15\n",
      "1066/1066 [==============================] - 0s 165us/sample - loss: 0.0488 - acc: 0.9916 - val_loss: 0.5079 - val_acc: 0.7751\n",
      "Epoch 15/15\n",
      "1066/1066 [==============================] - 0s 183us/sample - loss: 0.0381 - acc: 0.9934 - val_loss: 0.5197 - val_acc: 0.8035\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x27bad28aa08>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Conv1D model\n",
    "convolution_model.fit(x_train_indices, y_train, batch_size=64, callbacks=[monitor, checkpoint], epochs=15, validation_data=(x_test_indices, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "convolution_model.load_weights('best_weights_conv1d.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1066 samples, validate on 458 samples\n",
      "Epoch 1/15\n",
      "1066/1066 [==============================] - 15s 14ms/sample - loss: 0.6855 - acc: 0.8340 - val_loss: 0.6745 - val_acc: 0.8231\n",
      "Epoch 2/15\n",
      "1066/1066 [==============================] - 14s 13ms/sample - loss: 0.6535 - acc: 0.8377 - val_loss: 0.6234 - val_acc: 0.8231\n",
      "Epoch 3/15\n",
      "1066/1066 [==============================] - 13s 12ms/sample - loss: 0.5428 - acc: 0.8377 - val_loss: 0.4917 - val_acc: 0.8231\n",
      "Epoch 4/15\n",
      "1066/1066 [==============================] - 13s 12ms/sample - loss: 0.4602 - acc: 0.8377 - val_loss: 0.4709 - val_acc: 0.8231\n",
      "Epoch 5/15\n",
      "1066/1066 [==============================] - 13s 12ms/sample - loss: 0.4411 - acc: 0.8396 - val_loss: 0.4633 - val_acc: 0.8231\n",
      "Epoch 6/15\n",
      "1066/1066 [==============================] - 14s 14ms/sample - loss: 0.4363 - acc: 0.8443 - val_loss: 0.4636 - val_acc: 0.8231\n",
      "Epoch 7/15\n",
      "1066/1066 [==============================] - 15s 14ms/sample - loss: 0.4316 - acc: 0.8443 - val_loss: 0.4626 - val_acc: 0.8253\n",
      "Epoch 8/15\n",
      "1066/1066 [==============================] - 13s 12ms/sample - loss: 0.4302 - acc: 0.8452 - val_loss: 0.4616 - val_acc: 0.8231\n",
      "Epoch 9/15\n",
      "1066/1066 [==============================] - 14s 13ms/sample - loss: 0.4282 - acc: 0.8462 - val_loss: 0.4649 - val_acc: 0.8210\n",
      "Epoch 10/15\n",
      "1066/1066 [==============================] - 13s 12ms/sample - loss: 0.4269 - acc: 0.8462 - val_loss: 0.4650 - val_acc: 0.8210\n",
      "Epoch 11/15\n",
      "1066/1066 [==============================] - 13s 12ms/sample - loss: 0.4251 - acc: 0.8471 - val_loss: 0.4642 - val_acc: 0.8231\n",
      "Epoch 12/15\n",
      "1066/1066 [==============================] - 14s 13ms/sample - loss: 0.4255 - acc: 0.8480 - val_loss: 0.4664 - val_acc: 0.8210\n",
      "Epoch 13/15\n",
      "1066/1066 [==============================] - 13s 12ms/sample - loss: 0.4242 - acc: 0.8480 - val_loss: 0.4701 - val_acc: 0.8210\n",
      "Epoch 14/15\n",
      "1066/1066 [==============================] - 13s 12ms/sample - loss: 0.4254 - acc: 0.8480 - val_loss: 0.4671 - val_acc: 0.8210\n",
      "Epoch 15/15\n",
      "1066/1066 [==============================] - 13s 12ms/sample - loss: 0.4222 - acc: 0.8490 - val_loss: 0.4660 - val_acc: 0.8210\n"
     ]
    }
   ],
   "source": [
    "# LSTM model\n",
    "adam = tf.keras.optimizers.Adam(learning_rate = 0.0001)\n",
    "model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-6, patience=10, verbose=2, mode='auto')\n",
    "checkpoint = ModelCheckpoint(filepath=\"best_weights_lstm.hdf5\", verbose=0, save_best_only=True)\n",
    "\n",
    "model.fit(x_train_indices, y_train, batch_size=64, callbacks=[monitor, checkpoint], epochs=15, validation_data=(x_test_indices, y_test))\n",
    "\n",
    "model.load_weights('best_weights_lstm.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_test_indices = tokenizer.texts_to_sequences(x_test)\n",
    "# x_test_indices = pad_sequences(x_test_indices, maxlen=max_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "458/458 [==============================] - 5s 11ms/sample - loss: 0.4616 - acc: 0.8231\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.46160733075121085, 0.8231441]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test_indices, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "458/458 [==============================] - 0s 175us/sample - loss: 0.4572 - acc: 0.8166\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.457215733663484, 0.8165939]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convolution_model.evaluate(x_test_indices, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform CNN predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = convolution_model.predict(x_test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'podcast discussing vaccinations need help ! '"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = np.random.randint(0, len(x_test))\n",
    "x_test[n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted sentiment is negative\n",
      "correct sentiment is positive\n"
     ]
    }
   ],
   "source": [
    "if predictions[n] > 0.5:\n",
    "    print('predicted sentiment is positive')\n",
    "else:\n",
    "    print('predicted sentiment is negative')\n",
    "    \n",
    "if y_test[n] == 1:\n",
    "    print('correct sentiment is positive')\n",
    "else:\n",
    "    print('correct sentiment is negative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3011142]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(predictions[n])\n",
    "print(y_test[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "convolution_model.save_weights('best_weights_conv1d.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_tokens = tokenizer.texts_to_sequences(corpus_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_corpus\n",
    "data = predict_sentiments(data, corpus_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['text', 'sentiment', 'sentiment score', 'predicted sentiment']].to_csv('cnn_prediction.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment score</th>\n",
       "      <th>predicted sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>health canada approves astrazeneca covid - 19 ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.387547</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>covid - 19 canada : vaccination passports near...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.068375</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>coronavirus variants fuel canada third wave</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.028369</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>canadian government extend covid - 19 emergenc...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.096703</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>canada : pfizer extremely committed meeting va...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.706440</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1519</th>\n",
       "      <td>still 100 000 deaths measles every year world ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.063665</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1520</th>\n",
       "      <td>qualifies something toxin ppb even ppm toxins ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.082826</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1521</th>\n",
       "      <td>answer question said cannot cause damage body ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.092884</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1522</th>\n",
       "      <td>yeah long time ago vaccines weren t safe today...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.299412</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523</th>\n",
       "      <td>no one ever hurt mercury vaccine ever</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.088881</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1524 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text sentiment  \\\n",
       "0     health canada approves astrazeneca covid - 19 ...  positive   \n",
       "1     covid - 19 canada : vaccination passports near...  negative   \n",
       "2           coronavirus variants fuel canada third wave  negative   \n",
       "3     canadian government extend covid - 19 emergenc...  negative   \n",
       "4     canada : pfizer extremely committed meeting va...  positive   \n",
       "...                                                 ...       ...   \n",
       "1519  still 100 000 deaths measles every year world ...  negative   \n",
       "1520  qualifies something toxin ppb even ppm toxins ...  negative   \n",
       "1521  answer question said cannot cause damage body ...  negative   \n",
       "1522  yeah long time ago vaccines weren t safe today...  positive   \n",
       "1523             no one ever hurt mercury vaccine ever   negative   \n",
       "\n",
       "      sentiment score predicted sentiment  \n",
       "0            0.387547            negative  \n",
       "1            0.068375            negative  \n",
       "2            0.028369            negative  \n",
       "3            0.096703            negative  \n",
       "4            0.706440            positive  \n",
       "...               ...                 ...  \n",
       "1519         0.063665            negative  \n",
       "1520         0.082826            negative  \n",
       "1521         0.092884            negative  \n",
       "1522         0.299412            negative  \n",
       "1523         0.088881            negative  \n",
       "\n",
       "[1524 rows x 4 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.3875471 ]\n",
      " [0.06837532]\n",
      " [0.02836946]\n",
      " ...\n",
      " [0.09288406]\n",
      " [0.29941165]\n",
      " [0.08888111]]\n"
     ]
    }
   ],
   "source": [
    "# making predictions over the entire dataset\n",
    "corpus_tokens = pad_sequences(corpus_tokens, maxlen=max_len, padding='post')\n",
    "corpus_predictions = convolution_model.predict(corpus_tokens)\n",
    "print(corpus_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the predictions to binary, 1=pos, 0=neg\n",
    "binary_pred = []\n",
    "for i in corpus_predictions:\n",
    "    if i >= .5:\n",
    "        i = 1 \n",
    "        binary_pred.append(i) \n",
    "    else:\n",
    "        i = 0\n",
    "        binary_pred.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Model Evaluation\n",
    "As a classification model, this model will be evaluated on the following metrics: \n",
    " * Accuracy\n",
    " * Precision\n",
    " * Recall\n",
    " * F1 Score\n",
    " * Log Loss\n",
    " * Confusion Matrix\n",
    " * ROC Curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Square Error\n",
    "\n",
    "The mean square error is the sum of the squared differences between the prediction ($\\hat{y}$) and the expected ($y$).  MSE values are not of a particular unit.  If an MSE value has decreased for a model, that is good. Low MSE values are desired.\n",
    "\n",
    "$ \\text{MSE} = \\frac{1}{n} \\sum_{i=1}^n \\left(\\hat{y}_i - y_i\\right)^2 $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (MSE): 0.07677165354330709\n"
     ]
    }
   ],
   "source": [
    "# Measure MSE error.  \n",
    "score = metrics.mean_squared_error(binary_pred,y)\n",
    "print(\"Final score (MSE): {}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Root Mean Square Error\n",
    "\n",
    "The root mean square (RMSE) is essentially the square root of the MSE.  Because of this, the RMSE error is in the same units as the training data outcome. Low RMSE values are desired.\n",
    "\n",
    "$ \\text{RMSE} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^n \\left(\\hat{y}_i - y_i\\right)^2} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE): 0.277076981258471\n"
     ]
    }
   ],
   "source": [
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score = np.sqrt(metrics.mean_squared_error(binary_pred,y))\n",
    "print(\"Final score (RMSE): {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9232283464566929\n",
      "Averaged F1: 0.914750899445088\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      1270\n",
      "           1       0.96      0.56      0.71       254\n",
      "\n",
      "    accuracy                           0.92      1524\n",
      "   macro avg       0.94      0.78      0.83      1524\n",
      "weighted avg       0.93      0.92      0.91      1524\n",
      "\n",
      "Log Loss: 2.6516021232212155\n"
     ]
    }
   ],
   "source": [
    "score = metrics.accuracy_score(y, binary_pred)\n",
    "print('Accuracy: {}'.format(score))\n",
    "\n",
    "f1 = metrics.f1_score(y, binary_pred, average='weighted')\n",
    "print('Averaged F1: {}'.format(f1))\n",
    "\n",
    "#accuracy, precision, recall, f1 score\n",
    "print(metrics.classification_report(y, binary_pred))\n",
    "\n",
    "#log loss\n",
    "logLoss = metrics.log_loss(y, binary_pred)\n",
    "print('Log Loss: {}'.format(logLoss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1264    6]\n",
      " [ 111  143]]\n",
      "Plotting confusion matrix\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      1270\n",
      "           1       0.96      0.56      0.71       254\n",
      "\n",
      "    accuracy                           0.92      1524\n",
      "   macro avg       0.94      0.78      0.83      1524\n",
      "weighted avg       0.93      0.92      0.91      1524\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y, binary_pred)\n",
    "print(cm)\n",
    "\n",
    "\n",
    "print('Plotting confusion matrix')\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cm, ['normal','intruder'])\n",
    "plt.show()\n",
    "\n",
    "print(classification_report(y, binary_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform LSTM predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.16953546]\n",
      " [0.16953695]\n",
      " [0.16953436]\n",
      " ...\n",
      " [0.16953605]\n",
      " [0.16953212]\n",
      " [0.16953436]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1524"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making predictions over the entire dataset\n",
    "corpus_tokens = pad_sequences(corpus_tokens, maxlen=max_len, padding='post')\n",
    "corpus_lstm_predictions = model.predict(corpus_tokens)\n",
    "print(corpus_lstm_predictions)\n",
    "len(corpus_lstm_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the predictions to binary, 1=pos, 0=neg\n",
    "binary_pred2 = []\n",
    "for i in corpus_lstm_predictions:\n",
    "    if i >= .5:\n",
    "        i = 1 \n",
    "        binary_pred2.append(i) \n",
    "    else:\n",
    "        i = 0\n",
    "        binary_pred2.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating LSTM Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Square Error\n",
    "\n",
    "The mean square error is the sum of the squared differences between the prediction ($\\hat{y}$) and the expected ($y$).  MSE values are not of a particular unit.  If an MSE value has decreased for a model, that is good. Low MSE values are desired.\n",
    "\n",
    "$ \\text{MSE} = \\frac{1}{n} \\sum_{i=1}^n \\left(\\hat{y}_i - y_i\\right)^2 $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (MSE): 0.16141732283464566\n"
     ]
    }
   ],
   "source": [
    "# Measure MSE error.  \n",
    "score = metrics.mean_squared_error(binary_pred2,y)\n",
    "print(\"Final score (MSE): {}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Root Mean Square Error\n",
    "\n",
    "The root mean square (RMSE) is essentially the square root of the MSE.  Because of this, the RMSE error is in the same units as the training data outcome. Low RMSE values are desired.\n",
    "\n",
    "$ \\text{RMSE} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^n \\left(\\hat{y}_i - y_i\\right)^2} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE): 0.4017677473798085\n"
     ]
    }
   ],
   "source": [
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score = np.sqrt(metrics.mean_squared_error(binary_pred2,y))\n",
    "print(\"Final score (RMSE): {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4017677473798085\n",
      "Averaged F1: 0.7710619122257052\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      1270\n",
      "           1       0.90      0.04      0.07       254\n",
      "\n",
      "    accuracy                           0.84      1524\n",
      "   macro avg       0.87      0.52      0.49      1524\n",
      "weighted avg       0.85      0.84      0.77      1524\n",
      "\n",
      "Log Loss: 5.575157344321168\n"
     ]
    }
   ],
   "source": [
    "score1 = metrics.accuracy_score(y, binary_pred2)\n",
    "print('Accuracy: {}'.format(score))\n",
    "\n",
    "f1 = metrics.f1_score(y, binary_pred2, average='weighted')\n",
    "print('Averaged F1: {}'.format(f1))\n",
    "\n",
    "#accuracy, precision, recall, f1 score\n",
    "print(metrics.classification_report(y, binary_pred2))\n",
    "\n",
    "#log loss\n",
    "logLoss = metrics.log_loss(y, binary_pred2)\n",
    "print('Log Loss: {}'.format(logLoss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1269    1]\n",
      " [ 245    9]]\n",
      "Plotting confusion matrix\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      1270\n",
      "           1       0.90      0.04      0.07       254\n",
      "\n",
      "    accuracy                           0.84      1524\n",
      "   macro avg       0.87      0.52      0.49      1524\n",
      "weighted avg       0.85      0.84      0.77      1524\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y, binary_pred2)\n",
    "print(cm)\n",
    "\n",
    "\n",
    "print('Plotting confusion matrix')\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cm, ['normal','intruder'])\n",
    "plt.show()\n",
    "\n",
    "print(classification_report(y, binary_pred2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
