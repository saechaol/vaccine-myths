{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noah Venethongkham, 219660117\n",
    "# Ashley Thor, 219334909\n",
    "# Lucas Saechao, 218794239\n",
    "# CSC 180 - Intelligent Systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\19165\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# matplotlib\n",
    "%matplotlib inline\n",
    "from matplotlib.pyplot import figure, show\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# numpy and pandas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "\n",
    "# scikit learn\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, log_loss\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.utils import column_or_1d\n",
    "import sklearn.feature_extraction.text as sk_text\n",
    "import skimage.transform\n",
    "\n",
    "# natural language toolkit\n",
    "# run pip install nltk\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.test.utils import get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# tensorflow and keras\n",
    "from tensorflow.keras import optimizers, regularizers\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.layers import LSTM, Input, Dense, Activation, Flatten, Dropout, Conv1D, Conv2D, GlobalMaxPooling1D, MaxPooling1D, MaxPooling2D, Embedding\n",
    "#from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# run pip install np_utils\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# python libraries\n",
    "from collections.abc import Sequence\n",
    "import requests\n",
    "import pathlib\n",
    "import shutil\n",
    "import string\n",
    "import json\n",
    "import time\n",
    "import csv\n",
    "import io\n",
    "import os\n",
    "import re\n",
    "\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode text values to dummy variables(i.e. [1,0,0],[0,1,0],[0,0,1] for red,green,blue)\n",
    "def encode_text_dummy(df, name):\n",
    "    dummies = pd.get_dummies(df[name])\n",
    "    for x in dummies.columns:\n",
    "        dummy_name = \"{}-{}\".format(name, x)\n",
    "        df[dummy_name] = dummies[x]\n",
    "    df.drop(name, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# Encode text values to indexes(i.e. [1],[2],[3] for red,green,blue).\n",
    "def encode_text_index(df, name):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df[name] = le.fit_transform(df[name])\n",
    "    return le.classes_\n",
    "\n",
    "\n",
    "# Encode a numeric column as zscores\n",
    "def encode_numeric_zscore(df, name, mean=None, sd=None):\n",
    "    if mean is None:\n",
    "        mean = df[name].mean()\n",
    "    if sd is None:\n",
    "        sd = df[name].std()\n",
    "    df[name] = (df[name] - mean) / sd\n",
    "\n",
    "\n",
    "# Convert all missing values in the specified column to the median\n",
    "def missing_median(df, name):\n",
    "    med = df[name].median()\n",
    "    df[name] = df[name].fillna(med)\n",
    "\n",
    "\n",
    "# Convert all missing values in the specified column to the default\n",
    "def missing_default(df, name, default_value):\n",
    "    df[name] = df[name].fillna(default_value)\n",
    "\n",
    "\n",
    "# Convert a Pandas dataframe to the x,y inputs that TensorFlow needs\n",
    "def to_xy(df, target):\n",
    "    result = []\n",
    "    for x in df.columns:\n",
    "        if x != target:\n",
    "            result.append(x)\n",
    "    # find out the type of the target column. \n",
    "    target_type = df[target].dtypes\n",
    "    target_type = target_type[0] if isinstance(target_type, Sequence) else target_type\n",
    "    # Encode to int for classification, float otherwise. TensorFlow likes 32 bits.\n",
    "    if target_type in (np.int64, np.int32):\n",
    "        # Classification\n",
    "        dummies = pd.get_dummies(df[target])\n",
    "        return df[result].values.astype(np.float32), dummies.values.astype(np.float32)\n",
    "    else:\n",
    "        # Regression\n",
    "        return df[result].values.astype(np.float32), df[target].values.astype(np.float32)\n",
    "\n",
    "# Nicely formatted time string\n",
    "def hms_string(sec_elapsed):\n",
    "    h = int(sec_elapsed / (60 * 60))\n",
    "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
    "    s = sec_elapsed % 60\n",
    "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)\n",
    "\n",
    "\n",
    "# Regression chart.\n",
    "def chart_regression(pred,y,sort=True):\n",
    "    t = pd.DataFrame({'pred' : pred, 'y' : y.flatten()})\n",
    "    if sort:\n",
    "        t.sort_values(by=['y'],inplace=True)\n",
    "    a = plt.plot(t['y'].tolist(),label='expected')\n",
    "    b = plt.plot(t['pred'].tolist(),label='prediction')\n",
    "    plt.ylabel('output')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Remove all rows where the specified column is +/- sd standard deviations\n",
    "def remove_outliers(df, name, sd):\n",
    "    drop_rows = df.index[(np.abs(df[name] - df[name].mean()) >= (sd * df[name].std()))]\n",
    "    df.drop(drop_rows, axis=0, inplace=True)\n",
    "\n",
    "\n",
    "# Encode a column to a range between normalized_low and normalized_high.\n",
    "def encode_numeric_range(df, name, normalized_low=-1, normalized_high=1,\n",
    "                         data_low=None, data_high=None):\n",
    "    if data_low is None:\n",
    "        data_low = min(df[name])\n",
    "        data_high = max(df[name])\n",
    "    df[name] = ((df[name] - data_low) / (data_high - data_low)) \\\n",
    "               * (normalized_high - normalized_low) + normalized_low\n",
    "\n",
    "# Plots a confusion matrix for the model\n",
    "def plot_confusion_matrix(cm, names, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(names))\n",
    "    plt.xticks(tick_marks, names, rotation=45)\n",
    "    plt.yticks(tick_marks, names)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "# Plot an ROC curve\n",
    "def plot_roc(pred, y):\n",
    "    fpr, tpr, thresholds = roc_curve(y, pred)\n",
    "    roc_area_under_curve = auc(fpr, tpr)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label='ROC curve (area = $0.2f)' % roc_area_under_curve)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC)')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show\n",
    " \n",
    "def text_to_word_list(text):\n",
    "    text = str(text)\n",
    "    text = text.lower()\n",
    "    \n",
    "    # clean text by regex\n",
    "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=><]\", \" \", text)\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"cannot \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\",\", \" \", text)\n",
    "    text = re.sub(r\"\\.\", \" \", text)\n",
    "    text = re.sub(r\"!\", \" ! \", text)\n",
    "    text = re.sub(r\"\\/\", \" \", text)\n",
    "    text = re.sub(r\"\\^\", \" ^ \", text)\n",
    "    text = re.sub(r\"\\+\", \" + \", text)\n",
    "    text = re.sub(r\"\\>\", \" \", text)\n",
    "    text = re.sub(r\"\\-\", \" - \", text)\n",
    "    text = re.sub(r\"\\=\", \" = \", text)\n",
    "    text = re.sub(r\"\\'\", \" \", text)\n",
    "    text = re.sub(r\"'\", \" \", text)\n",
    "    text = re.sub(r\"(\\d+)(k)\", \"\\g<1>000\", text)\n",
    "    text = re.sub(r\":\", \" : \", text)\n",
    "    text = re.sub(r\" e g \", \" eg \", text)\n",
    "    text = re.sub(r\" b g \", \" bg \", text)\n",
    "    text = re.sub(r\" u s \", \" american \", text)\n",
    "    text = re.sub(r\"\\0s\", \"0\", text)\n",
    "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
    "    text = re.sub(r\"e - mail\", \"email\", text)\n",
    "    text = re.sub(r\"covid19\", \"covid\", text)\n",
    "    text = re.sub(r\"covid-19\", \"covid\", text)\n",
    "    text = re.sub(r\"covid - 19\", \"covid\", text)\n",
    "    text = re.sub(r\"j k\", \"jk\", text)\n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "    text = re.sub('<.*?>', '', text)\n",
    "    text = text.split()\n",
    "    return text\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    stopwords_list = stopwords.words('english')\n",
    "    whitelist = [\"n't\", \"not\", \"no\"]\n",
    "    words = text.split()\n",
    "    words_clean = [word for word in words if (word not in stopwords_list or word in whitelist) and len(word) > 1]\n",
    "    return \" \".join(words_clean)\n",
    "    \n",
    "def read_glove_vector(glove_vec):\n",
    "    with open(glove_vec, 'r', encoding='utf-8') as f:\n",
    "        words = set()\n",
    "        word_to_vec_map = {}\n",
    "        for line in f:\n",
    "            w_line = line.split()\n",
    "            current_word = w_line[0]\n",
    "            word_to_vec_map[current_word] = np.array(w_line[1:], dtype=np.float64)\n",
    "    return word_to_vec_map\n",
    "    \n",
    "def lstm_model(input_shape):\n",
    "    x_indices = Input(input_shape)\n",
    "    embeddings = embedding_layer(x_indices)\n",
    "    x = LSTM(128, return_sequences=True)(embeddings)\n",
    "    x = Dropout(0.6)(x)\n",
    "    x = LSTM(128, return_sequences=True)(x)\n",
    "    x = Dropout(0.6)(x)\n",
    "    x = LSTM(128)(x)\n",
    "    x = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=x_indices, outputs=x)\n",
    "    return model\n",
    "\n",
    "def conv_model(input_shape):\n",
    "    x_indices = Input(input_shape)\n",
    "    embeddings = embedding_layer(x_indices)\n",
    "    x = Conv1D(512, 3, activation='relu')(embeddings)\n",
    "    x = MaxPooling1D(3)(x)\n",
    "    x = Conv1D(256, 3, activation='relu')(x)\n",
    "    x = MaxPooling1D(3)(x)\n",
    "    x = Conv1D(256, 3, activation='relu')(x)\n",
    "    x = Dropout(0.8)(x)\n",
    "    x = MaxPooling1D(3)(x)\n",
    "    x = GlobalMaxPooling1D()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=x_indices, outputs=x)\n",
    "    return model\n",
    "    \n",
    "def predict_sentiments(data, corpus):\n",
    "    data['sentiment score'] = 0\n",
    "    corpus = pad_sequences(corpus, maxlen=max_len, padding='post')\n",
    "    pred = model.predict(corpus)\n",
    "    data['sentiment score'] = pred\n",
    "    pred_sentiment = np.array(list(map(lambda x: 'positive' if x > 0.5 else 'negative', pred)))\n",
    "    data['predicted sentiment'] = 0\n",
    "    data['predicted sentiment'] = pred_sentiment\n",
    "    return data\n",
    "    \n",
    "# Beep if on a windows machine\n",
    "if os.name == 'nt':\n",
    "    def ding():\n",
    "        winsound.Beep(2000, 300)\n",
    "        winsound.Beep(2000, 300)\n",
    "        winsound.Beep(2000, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  title  \\\n",
      "0     Health Canada approves AstraZeneca COVID-19 va...   \n",
      "1     COVID-19 in Canada: 'Vaccination passports' a ...   \n",
      "2     Coronavirus variants could fuel Canada's third...   \n",
      "3     Canadian government to extend COVID-19 emergen...   \n",
      "4     Canada: Pfizer is 'extremely committed' to mee...   \n",
      "...                                                 ...   \n",
      "1465                                                      \n",
      "1466                                                      \n",
      "1467                                                      \n",
      "1468                                                      \n",
      "1469                                                      \n",
      "\n",
      "                                                   body sentiment  \n",
      "0                                                        positive  \n",
      "1                                                                  \n",
      "2                                                                  \n",
      "3                                                        positive  \n",
      "4                                                        positive  \n",
      "...                                                 ...       ...  \n",
      "1465  The problem is the calculations themselves and...  positive  \n",
      "1466  I created the Vaxfact site using references to...            \n",
      "1467  >The information I provided is not wrong\\r\\n\\r...  positive  \n",
      "1468  Basically nothing.\\r\\n\\r\\n>Autoimmunity to the...  positive  \n",
      "1469  In this instance, yourself. Broader, that Vaxf...            \n",
      "\n",
      "[1470 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create pandas dataframe output file\n",
    "df_reddit = pd.read_csv('reddit_vm_labelled.csv', encoding=\"utf-8\")\n",
    "df_reddit = df_reddit[['title', 'body', 'sentiment']].fillna('')\n",
    "df_reddit['title'] = df_reddit['title'].replace(to_replace='Comment', value='')\n",
    "\n",
    "print(df_reddit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  title  \\\n",
      "0     Health Canada approves AstraZeneca COVID-19 va...   \n",
      "1     COVID-19 Canada: 'Vaccination passports' near ...   \n",
      "2     Coronavirus variants could fuel Canada's third...   \n",
      "3     Canadian government extend COVID-19 emergency ...   \n",
      "4     Canada: Pfizer 'extremely committed' meeting v...   \n",
      "...                                                 ...   \n",
      "1465                                                      \n",
      "1466                                                      \n",
      "1467                                                      \n",
      "1468                                                      \n",
      "1469                                                      \n",
      "\n",
      "                                                   body sentiment  \n",
      "0                                                        positive  \n",
      "1                                                                  \n",
      "2                                                                  \n",
      "3                                                        positive  \n",
      "4                                                        positive  \n",
      "...                                                 ...       ...  \n",
      "1465  The problem calculations idea layperson napkin...  positive  \n",
      "1466  created Vaxfact site using references reliable...            \n",
      "1467  >The information provided not wrong You've rep...  positive  \n",
      "1468  Basically nothing. >Autoimmunity central nervo...  positive  \n",
      "1469      In instance, yourself. Broader, Vaxfact site.            \n",
      "\n",
      "[1470 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "df_reddit.body = df_reddit.body.apply(remove_stopwords)\n",
    "df_reddit.title = df_reddit.title.apply(remove_stopwords)\n",
    "print(df_reddit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       positive\n",
       "1       negative\n",
       "2       negative\n",
       "3       positive\n",
       "4       positive\n",
       "          ...   \n",
       "1465    positive\n",
       "1466    negative\n",
       "1467    positive\n",
       "1468    positive\n",
       "1469    negative\n",
       "Name: sentiment, Length: 1470, dtype: object"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sentiment = df_reddit.sentiment\n",
    "df_sentiment.replace('', 'negative', inplace=True)\n",
    "df_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_title = df_reddit.title\n",
    "df_title.replace('', np.nan, inplace=True)\n",
    "df_title.to_frame(name=\"text\")\n",
    "df_body = df_reddit.body\n",
    "df_body.to_frame(name=\"text\")\n",
    "df_body.replace('', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Health Canada approves AstraZeneca COVID-19 va...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COVID-19 Canada: 'Vaccination passports' near ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Coronavirus variants could fuel Canada's third...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Canadian government extend COVID-19 emergency ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Canada: Pfizer 'extremely committed' meeting v...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1465</th>\n",
       "      <td>NaN</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1466</th>\n",
       "      <td>NaN</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1467</th>\n",
       "      <td>NaN</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1468</th>\n",
       "      <td>NaN</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1469</th>\n",
       "      <td>NaN</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1470 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title sentiment\n",
       "0     Health Canada approves AstraZeneca COVID-19 va...  positive\n",
       "1     COVID-19 Canada: 'Vaccination passports' near ...  negative\n",
       "2     Coronavirus variants could fuel Canada's third...  negative\n",
       "3     Canadian government extend COVID-19 emergency ...  positive\n",
       "4     Canada: Pfizer 'extremely committed' meeting v...  positive\n",
       "...                                                 ...       ...\n",
       "1465                                                NaN  positive\n",
       "1466                                                NaN  negative\n",
       "1467                                                NaN  positive\n",
       "1468                                                NaN  positive\n",
       "1469                                                NaN  negative\n",
       "\n",
       "[1470 rows x 2 columns]"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_title_sentiment = pd.concat([df_title, df_sentiment], axis=1)\n",
    "df_title_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1465</th>\n",
       "      <td>The problem calculations idea layperson napkin...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1466</th>\n",
       "      <td>created Vaxfact site using references reliable...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1467</th>\n",
       "      <td>&gt;The information provided not wrong You've rep...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1468</th>\n",
       "      <td>Basically nothing. &gt;Autoimmunity central nervo...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1469</th>\n",
       "      <td>In instance, yourself. Broader, Vaxfact site.</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1470 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   body sentiment\n",
       "0                                                   NaN  positive\n",
       "1                                                   NaN  negative\n",
       "2                                                   NaN  negative\n",
       "3                                                   NaN  positive\n",
       "4                                                   NaN  positive\n",
       "...                                                 ...       ...\n",
       "1465  The problem calculations idea layperson napkin...  positive\n",
       "1466  created Vaxfact site using references reliable...  negative\n",
       "1467  >The information provided not wrong You've rep...  positive\n",
       "1468  Basically nothing. >Autoimmunity central nervo...  positive\n",
       "1469      In instance, yourself. Broader, Vaxfact site.  negative\n",
       "\n",
       "[1470 rows x 2 columns]"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_body_sentiment = pd.concat([df_body, df_sentiment], axis=1)\n",
    "df_body_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Health Canada approves AstraZeneca COVID-19 va...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COVID-19 Canada: 'Vaccination passports' near ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Coronavirus variants could fuel Canada's third...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Canadian government extend COVID-19 emergency ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Canada: Pfizer 'extremely committed' meeting v...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>father five unvaccinated children. Am unfit pa...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>Love Them. Protect Them. Never Inject Them.</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>Vaccines Are Just Asping For Trouble</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>Dr. Harper explained presentation cervical can...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>Polio arose US period pesticide use skyrockete...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>443 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title sentiment\n",
       "0    Health Canada approves AstraZeneca COVID-19 va...  positive\n",
       "1    COVID-19 Canada: 'Vaccination passports' near ...  negative\n",
       "2    Coronavirus variants could fuel Canada's third...  negative\n",
       "3    Canadian government extend COVID-19 emergency ...  positive\n",
       "4    Canada: Pfizer 'extremely committed' meeting v...  positive\n",
       "..                                                 ...       ...\n",
       "438  father five unvaccinated children. Am unfit pa...  negative\n",
       "439        Love Them. Protect Them. Never Inject Them.  negative\n",
       "440               Vaccines Are Just Asping For Trouble  negative\n",
       "441  Dr. Harper explained presentation cervical can...  negative\n",
       "442  Polio arose US period pesticide use skyrockete...  negative\n",
       "\n",
       "[443 rows x 2 columns]"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_title_clean = df_title_sentiment.dropna().drop_duplicates().reset_index(drop=True)\n",
    "df_title_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Your OP. It's not myth. Only one vaccine conta...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Because Anti-Vaxxers no sense</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What mean \"your OP\". fairly new reddit.</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>When say there's no thimerasol, mean childhood...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The \"myth\" debunking regards childhood schedul...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1076</th>\n",
       "      <td>The problem calculations idea layperson napkin...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1077</th>\n",
       "      <td>created Vaxfact site using references reliable...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1078</th>\n",
       "      <td>&gt;The information provided not wrong You've rep...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1079</th>\n",
       "      <td>Basically nothing. &gt;Autoimmunity central nervo...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1080</th>\n",
       "      <td>In instance, yourself. Broader, Vaxfact site.</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1081 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   body sentiment\n",
       "0     Your OP. It's not myth. Only one vaccine conta...  negative\n",
       "1                         Because Anti-Vaxxers no sense  negative\n",
       "2               What mean \"your OP\". fairly new reddit.  negative\n",
       "3     When say there's no thimerasol, mean childhood...  negative\n",
       "4     The \"myth\" debunking regards childhood schedul...  positive\n",
       "...                                                 ...       ...\n",
       "1076  The problem calculations idea layperson napkin...  positive\n",
       "1077  created Vaxfact site using references reliable...  negative\n",
       "1078  >The information provided not wrong You've rep...  positive\n",
       "1079  Basically nothing. >Autoimmunity central nervo...  positive\n",
       "1080      In instance, yourself. Broader, Vaxfact site.  negative\n",
       "\n",
       "[1081 rows x 2 columns]"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_body_clean = df_body_sentiment.dropna().drop_duplicates().reset_index(drop=True)\n",
    "df_body_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corpus = pd.DataFrame(index=range(0, 1524), columns=['text', 'sentiment'], dtype='object')\n",
    "df_corpus_text = pd.concat([df_title_clean.title, df_body_clean.body])\n",
    "df_corpus_sentiment = pd.concat([df_title_clean.sentiment, df_body_clean.sentiment])\n",
    "df_corpus_text = df_corpus_text.to_frame(name='text')\n",
    "df_corpus_text.reset_index(inplace=True)\n",
    "df_corpus_sentiment = df_corpus_sentiment.to_frame(name='sentiment')\n",
    "df_corpus_sentiment.reset_index(inplace=True)\n",
    "df_corpus.text = df_corpus_text.text\n",
    "df_corpus.sentiment = df_corpus_sentiment.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Health Canada approves AstraZeneca COVID-19 va...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COVID-19 Canada: 'Vaccination passports' near ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Coronavirus variants could fuel Canada's third...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Canadian government extend COVID-19 emergency ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Canada: Pfizer 'extremely committed' meeting v...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment\n",
       "0  Health Canada approves AstraZeneca COVID-19 va...  positive\n",
       "1  COVID-19 Canada: 'Vaccination passports' near ...  negative\n",
       "2  Coronavirus variants could fuel Canada's third...  negative\n",
       "3  Canadian government extend COVID-19 emergency ...  positive\n",
       "4  Canada: Pfizer 'extremely committed' meeting v...  positive"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df_corpus.text\n",
    "sentiments = df_corpus.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_list = []\n",
    "for i in range(len(texts)):\n",
    "    corpus_list.append(texts[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(list(map(lambda x: 1 if x==\"positive\" else 0, sentiments)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 1, 1, 0])"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(corpus_list, y, test_size=0.3, random_state=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1066\n",
      "458\n",
      "1066\n",
      "458\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train))\n",
    "print(len(x_test))\n",
    "print(len(y_train))\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=25000)\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "word_to_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_file_loc = os.path.join(\n",
    "    os.path.expanduser('~'), '.keras/datasets/glove.6B.300d.txt'\n",
    ")\n",
    "word_to_vec_map = read_glove_vector(glove_file_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6619\n",
      "300\n",
      "(6620, 300)\n"
     ]
    }
   ],
   "source": [
    "vocab_len = len(word_to_index)\n",
    "embed_vector_len = word_to_vec_map['moon'].shape[0]\n",
    "emb_matrix = np.zeros((vocab_len + 1, embed_vector_len))\n",
    "print(vocab_len)\n",
    "print(embed_vector_len)\n",
    "print(emb_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word, index in word_to_index.items():\n",
    "    embedding_vec = word_to_vec_map.get(word)\n",
    "    if embedding_vec is not None:\n",
    "        emb_matrix[index, :] = embedding_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(\n",
    "    input_dim=vocab_len + 1,\n",
    "    output_dim=embed_vector_len,\n",
    "    input_length=max_len,\n",
    "    weights=[emb_matrix],\n",
    "    trainable=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_19 (InputLayer)        [(None, 150)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_9 (Embedding)      (None, 150, 300)          1986000   \n",
      "_________________________________________________________________\n",
      "lstm_21 (LSTM)               (None, 150, 128)          219648    \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 150, 128)          0         \n",
      "_________________________________________________________________\n",
      "lstm_22 (LSTM)               (None, 150, 128)          131584    \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 150, 128)          0         \n",
      "_________________________________________________________________\n",
      "lstm_23 (LSTM)               (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 2,468,945\n",
      "Trainable params: 482,945\n",
      "Non-trainable params: 1,986,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = lstm_model((max_len,))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_20 (InputLayer)        [(None, 150)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_9 (Embedding)      (None, 150, 300)          1986000   \n",
      "_________________________________________________________________\n",
      "conv1d_25 (Conv1D)           (None, 148, 512)          461312    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling (None, 49, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (None, 47, 256)           393472    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling (None, 15, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_27 (Conv1D)           (None, 13, 256)           196864    \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 13, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_26 (MaxPooling (None, 4, 256)            0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_7 (Glob (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 3,103,697\n",
      "Trainable params: 1,117,697\n",
      "Non-trainable params: 1,986,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "convolution_model = conv_model((max_len,))\n",
    "convolution_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_indices = tokenizer.texts_to_sequences(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1066, 150)\n"
     ]
    }
   ],
   "source": [
    "x_train_indices = pad_sequences(x_train_indices, maxlen=max_len, padding='post')\n",
    "print(x_train_indices.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = tf.keras.optimizers.Adam(learning_rate = 0.0001)\n",
    "convolution_model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "17/17 [==============================] - 2s 101ms/step - loss: 0.6157 - accuracy: 0.7098\n",
      "Epoch 2/15\n",
      "17/17 [==============================] - 2s 106ms/step - loss: 0.4313 - accuracy: 0.9084\n",
      "Epoch 3/15\n",
      "17/17 [==============================] - 2s 107ms/step - loss: 0.4024 - accuracy: 0.8909\n",
      "Epoch 4/15\n",
      "17/17 [==============================] - 2s 109ms/step - loss: 0.3579 - accuracy: 0.9019\n",
      "Epoch 5/15\n",
      "17/17 [==============================] - 2s 108ms/step - loss: 0.3202 - accuracy: 0.9080\n",
      "Epoch 6/15\n",
      "17/17 [==============================] - 2s 108ms/step - loss: 0.3250 - accuracy: 0.9029\n",
      "Epoch 7/15\n",
      "17/17 [==============================] - 2s 109ms/step - loss: 0.3115 - accuracy: 0.9037\n",
      "Epoch 8/15\n",
      "17/17 [==============================] - 2s 108ms/step - loss: 0.3150 - accuracy: 0.8991\n",
      "Epoch 9/15\n",
      "17/17 [==============================] - 2s 108ms/step - loss: 0.2872 - accuracy: 0.9021\n",
      "Epoch 10/15\n",
      "17/17 [==============================] - 2s 110ms/step - loss: 0.2644 - accuracy: 0.9111\n",
      "Epoch 11/15\n",
      "17/17 [==============================] - 2s 111ms/step - loss: 0.2335 - accuracy: 0.9281\n",
      "Epoch 12/15\n",
      "17/17 [==============================] - 2s 110ms/step - loss: 0.2511 - accuracy: 0.9184\n",
      "Epoch 13/15\n",
      "17/17 [==============================] - 2s 110ms/step - loss: 0.2227 - accuracy: 0.9183\n",
      "Epoch 14/15\n",
      "17/17 [==============================] - 2s 112ms/step - loss: 0.1754 - accuracy: 0.9443\n",
      "Epoch 15/15\n",
      "17/17 [==============================] - 2s 111ms/step - loss: 0.1988 - accuracy: 0.9280\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b562e07cc8>"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Conv1D model\n",
    "convolution_model.fit(x_train_indices, y_train, batch_size=64, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "17/17 [==============================] - 17s 797ms/step - loss: 0.6876 - accuracy: 0.8905\n",
      "Epoch 2/15\n",
      "17/17 [==============================] - 14s 806ms/step - loss: 0.6505 - accuracy: 0.9038\n",
      "Epoch 3/15\n",
      "17/17 [==============================] - 14s 806ms/step - loss: 0.4844 - accuracy: 0.9130\n",
      "Epoch 4/15\n",
      "17/17 [==============================] - 14s 802ms/step - loss: 0.3337 - accuracy: 0.9024\n",
      "Epoch 5/15\n",
      "17/17 [==============================] - 14s 805ms/step - loss: 0.3074 - accuracy: 0.9085\n",
      "Epoch 6/15\n",
      "17/17 [==============================] - 14s 829ms/step - loss: 0.3130 - accuracy: 0.9016\n",
      "Epoch 7/15\n",
      "17/17 [==============================] - 14s 831ms/step - loss: 0.2778 - accuracy: 0.9197\n",
      "Epoch 8/15\n",
      "17/17 [==============================] - 14s 822ms/step - loss: 0.2776 - accuracy: 0.9215\n",
      "Epoch 9/15\n",
      "17/17 [==============================] - 14s 828ms/step - loss: 0.2897 - accuracy: 0.9117\n",
      "Epoch 10/15\n",
      "17/17 [==============================] - 14s 817ms/step - loss: 0.2732 - accuracy: 0.9231\n",
      "Epoch 11/15\n",
      " 4/17 [======>.......................] - ETA: 10s - loss: 0.3642 - accuracy: 0.8848"
     ]
    }
   ],
   "source": [
    "# LSTM model\n",
    "adam = tf.keras.optimizers.Adam(learning_rate = 0.0001)\n",
    "model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x_train_indices, y_train, batch_size=64, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_indices = tokenizer.texts_to_sequences(x_test)\n",
    "x_test_indices = pad_sequences(x_test_indices, maxlen=max_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test_indices, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convolution_model.evaluate(x_test_indices, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = convolution_model.predict(x_test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = np.random.randint(0, len(x_test))\n",
    "x_test[n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if predictions[n] > 0.5:\n",
    "    print('predicted sentiment is positive')\n",
    "else:\n",
    "    print('predicted sentiment is negative')\n",
    "    \n",
    "if y_test[n] == 1:\n",
    "    print('correct sentiment is positive')\n",
    "else:\n",
    "    print('correct sentiment is negative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictions[n])\n",
    "print(y_test[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convolution_model.save_weights('best_weights_conv1d.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_tokens = tokenizer.texts_to_sequences(corpus_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_corpus\n",
    "data = predict_sentiments(data, corpus_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['text', 'sentiment', 'sentiment score', 'predicted sentiment']].to_csv('prediction.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
