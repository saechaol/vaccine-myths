{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noah Venethongkham, 219660117\n",
    "# Ashley Thor, 219334909\n",
    "# Lucas Saechao, 218794239\n",
    "# CSC 180 - Intelligent Systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Noah\\anaconda3\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\Noah\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Noah\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Noah\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Noah\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Noah\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Noah\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Noah\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Noah\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Noah\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Noah\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Noah\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Noah\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Noah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# matplotlib\n",
    "%matplotlib inline\n",
    "from matplotlib.pyplot import figure, show\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# numpy and pandas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "\n",
    "# scikit learn\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, log_loss\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.utils import column_or_1d\n",
    "import sklearn.feature_extraction.text as sk_text\n",
    "import skimage.transform\n",
    "\n",
    "# natural language toolkit\n",
    "# run pip install nltk\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.test.utils import get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# tensorflow and keras\n",
    "from tensorflow.keras import optimizers, regularizers\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.layers import LSTM, Input, Dense, Activation, Flatten, Dropout, Conv1D, Conv2D, GlobalMaxPooling1D, MaxPooling1D, MaxPooling2D, Embedding\n",
    "#from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# run pip install np_utils\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# python libraries\n",
    "from collections.abc import Sequence\n",
    "import requests\n",
    "import pathlib\n",
    "import shutil\n",
    "import string\n",
    "import json\n",
    "import time\n",
    "import csv\n",
    "import io\n",
    "import os\n",
    "import re\n",
    "\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode text values to dummy variables(i.e. [1,0,0],[0,1,0],[0,0,1] for red,green,blue)\n",
    "def encode_text_dummy(df, name):\n",
    "    dummies = pd.get_dummies(df[name])\n",
    "    for x in dummies.columns:\n",
    "        dummy_name = \"{}-{}\".format(name, x)\n",
    "        df[dummy_name] = dummies[x]\n",
    "    df.drop(name, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# Encode text values to indexes(i.e. [1],[2],[3] for red,green,blue).\n",
    "def encode_text_index(df, name):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df[name] = le.fit_transform(df[name])\n",
    "    return le.classes_\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Encode a numeric column as zscores\n",
    "def encode_numeric_zscore(df, name, mean=None, sd=None):\n",
    "    if mean is None:\n",
    "        mean = df[name].mean()\n",
    "    if sd is None:\n",
    "        sd = df[name].std()\n",
    "    df[name] = (df[name] - mean) / sd\n",
    "\n",
    "\n",
    "# Convert all missing values in the specified column to the median\n",
    "def missing_median(df, name):\n",
    "    med = df[name].median()\n",
    "    df[name] = df[name].fillna(med)\n",
    "\n",
    "\n",
    "# Convert all missing values in the specified column to the default\n",
    "def missing_default(df, name, default_value):\n",
    "    df[name] = df[name].fillna(default_value)\n",
    "\n",
    "\n",
    "# Convert a Pandas dataframe to the x,y inputs that TensorFlow needs\n",
    "def to_xy(df, target):\n",
    "    result = []\n",
    "    for x in df.columns:\n",
    "        if x != target:\n",
    "            result.append(x)\n",
    "    # find out the type of the target column. \n",
    "    target_type = df[target].dtypes\n",
    "    target_type = target_type[0] if isinstance(target_type, Sequence) else target_type\n",
    "    # Encode to int for classification, float otherwise. TensorFlow likes 32 bits.\n",
    "    if target_type in (np.int64, np.int32):\n",
    "        # Classification\n",
    "        dummies = pd.get_dummies(df[target])\n",
    "        return df[result].values.astype(np.float32), dummies.values.astype(np.float32)\n",
    "    else:\n",
    "        # Regression\n",
    "        return df[result].values.astype(np.float32), df[target].values.astype(np.float32)\n",
    "\n",
    "# Nicely formatted time string\n",
    "def hms_string(sec_elapsed):\n",
    "    h = int(sec_elapsed / (60 * 60))\n",
    "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
    "    s = sec_elapsed % 60\n",
    "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)\n",
    "\n",
    "\n",
    "# Regression chart.\n",
    "def chart_regression(pred,y,sort=True):\n",
    "    t = pd.DataFrame({'pred' : pred, 'y' : y.flatten()})\n",
    "    if sort:\n",
    "        t.sort_values(by=['y'],inplace=True)\n",
    "    a = plt.plot(t['y'].tolist(),label='expected')\n",
    "    b = plt.plot(t['pred'].tolist(),label='prediction')\n",
    "    plt.ylabel('output')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Remove all rows where the specified column is +/- sd standard deviations\n",
    "def remove_outliers(df, name, sd):\n",
    "    drop_rows = df.index[(np.abs(df[name] - df[name].mean()) >= (sd * df[name].std()))]\n",
    "    df.drop(drop_rows, axis=0, inplace=True)\n",
    "\n",
    "\n",
    "# Encode a column to a range between normalized_low and normalized_high.\n",
    "def encode_numeric_range(df, name, normalized_low=-1, normalized_high=1,\n",
    "                         data_low=None, data_high=None):\n",
    "    if data_low is None:\n",
    "        data_low = min(df[name])\n",
    "        data_high = max(df[name])\n",
    "    df[name] = ((df[name] - data_low) / (data_high - data_low)) \\\n",
    "               * (normalized_high - normalized_low) + normalized_low\n",
    "\n",
    "# Plots a confusion matrix for the model\n",
    "def plot_confusion_matrix(cm, names, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(names))\n",
    "    plt.xticks(tick_marks, names, rotation=45)\n",
    "    plt.yticks(tick_marks, names)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "# Plot an ROC curve\n",
    "def plot_roc(pred, y):\n",
    "    fpr, tpr, thresholds = roc_curve(y, pred)\n",
    "    roc_area_under_curve = auc(fpr, tpr)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label='ROC curve (area = $0.2f)' % roc_area_under_curve)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC)')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show\n",
    " \n",
    "def text_to_word_list(text):\n",
    "    text = str(text)\n",
    "    text = text.lower()\n",
    "    text = remove_stopwords(text)\n",
    "    \n",
    "    # clean text by regex\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    text = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'\\w+:\\/{2}[\\d\\w-]+(\\.[\\d\\w-]+)*(?:(?:\\/[^\\s/]*))*', '', text)\n",
    "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=><]\", \" \", text)\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"cannot \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\",\", \" \", text)\n",
    "    text = re.sub(r\"\\.\", \" \", text)\n",
    "    text = re.sub(r\"!\", \" ! \", text)\n",
    "    text = re.sub(r\"\\/\", \" \", text)\n",
    "    text = re.sub(r\"\\^\", \" ^ \", text)\n",
    "    text = re.sub(r\"\\+\", \" + \", text)\n",
    "    text = re.sub(r\"\\>\", \" \", text)\n",
    "    text = re.sub(r\"\\-\", \" - \", text)\n",
    "    text = re.sub(r\"\\=\", \" = \", text)\n",
    "    text = re.sub(r\"\\'\", \" \", text)\n",
    "    text = re.sub(r\"'\", \" \", text)\n",
    "    text = re.sub(r\"(\\d+)(k)\", \"\\g<1>000\", text)\n",
    "    text = re.sub(r\":\", \" : \", text)\n",
    "    text = re.sub(r\" e g \", \" eg \", text)\n",
    "    text = re.sub(r\" b g \", \" bg \", text)\n",
    "    text = re.sub(r\" u s \", \" american \", text)\n",
    "    text = re.sub(r\"\\0s\", \"0\", text)\n",
    "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
    "    text = re.sub(r\"e - mail\", \"email\", text)\n",
    "    text = re.sub(r\"covid19\", \"covid\", text)\n",
    "    text = re.sub(r\"j k\", \"jk\", text)\n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "    text = re.sub('_', ' ', text)\n",
    "    return text\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    stopwords_list = stopwords.words('english')\n",
    "    whitelist = [\"n't\", \"not\", \"no\"]\n",
    "    words = text.split()\n",
    "    words_clean = [word for word in words if (word not in stopwords_list or word in whitelist) and len(word) > 1]\n",
    "    return \" \".join(words_clean)\n",
    "    \n",
    "def remove_stop_manual(data):\n",
    "    stopwords = [ \"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"as\", \"at\", \"be\", \"because\", \n",
    "             \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"could\", \"did\", \"do\", \"does\", \"doing\", \"down\", \"during\",\n",
    "             \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"has\", \"have\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\", \n",
    "             \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\",\n",
    "             \"is\", \"it\", \"it's\", \"its\", \"itself\", \"let's\", \"me\", \"more\", \"most\", \"my\", \"myself\", \"nor\", \"of\", \"on\", \"once\", \"only\", \"or\",\n",
    "             \"other\", \"ought\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"she\", \"she'd\", \"she'll\", \"she's\", \"should\", \n",
    "             \"so\", \"some\", \"such\", \"than\", \"that\", \"that's\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"there's\",\n",
    "             \"these\", \"they\", \"they'd\", \"they'll\", \"they're\", \"they've\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\",\n",
    "             \"very\", \"was\", \"we\", \"we'd\", \"we'll\", \"we're\", \"we've\", \"were\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\",\n",
    "             \"which\", \"while\", \"who\", \"who's\", \"whom\", \"why\", \"why's\", \"with\", \"would\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\",\n",
    "             \"your\", \"yours\", \"yourself\", \"yourselves\" ]\n",
    "    data = data.apply(lambda x : ' '.join([word for word in x.split() if word not in (stopwords)]))\n",
    "    return data\n",
    "    \n",
    "def read_glove_vector(glove_vec):\n",
    "    with open(glove_vec, 'r', encoding='utf-8') as f:\n",
    "        words = set()\n",
    "        word_to_vec_map = {}\n",
    "        for line in f:\n",
    "            w_line = line.split()\n",
    "            current_word = w_line[0]\n",
    "            word_to_vec_map[current_word] = np.array(w_line[1:], dtype=np.float64)\n",
    "    return word_to_vec_map\n",
    "    \n",
    "def lstm_model(input_shape):\n",
    "    x_indices = Input(input_shape)\n",
    "    embeddings = embedding_layer(x_indices)\n",
    "    x = LSTM(128, return_sequences=True)(embeddings)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = LSTM(128, return_sequences=True)(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = LSTM(128)(x)\n",
    "    x = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=x_indices, outputs=x)\n",
    "    return model\n",
    "\n",
    "def conv_model(input_shape):\n",
    "    x_indices = Input(input_shape)\n",
    "    embeddings = embedding_layer(x_indices)\n",
    "    x = Conv1D(512, 3, activation='relu')(embeddings)\n",
    "    x = MaxPooling1D(3)(x)\n",
    "    x = Conv1D(256, 3, activation='relu')(x)\n",
    "    x = MaxPooling1D(3)(x)\n",
    "    x = Conv1D(256, 3, activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = MaxPooling1D(3)(x)\n",
    "    x = GlobalMaxPooling1D()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=x_indices, outputs=x)\n",
    "    return model\n",
    "    \n",
    "def predict_sentiments(data, corpus):\n",
    "    data['sentiment score'] = 0\n",
    "    corpus = pad_sequences(corpus, maxlen=max_len, padding='post')\n",
    "    pred = convolution_model.predict(corpus)\n",
    "    data['sentiment score'] = pred\n",
    "    pred_sentiment = np.array(list(map(lambda x: 'positive' if x > 0.5 else 'negative', pred)))\n",
    "    data['predicted sentiment'] = 0\n",
    "    data['predicted sentiment'] = pred_sentiment\n",
    "    return data\n",
    "    \n",
    "# Beep if on a windows machine\n",
    "if os.name == 'nt':\n",
    "    def ding():\n",
    "        winsound.Beep(2000, 300)\n",
    "        winsound.Beep(2000, 300)\n",
    "        winsound.Beep(2000, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_binary(input_str):\n",
    "    out = 0 if input_str == 'negative.' else 1\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  title  \\\n",
      "0     Health Canada approves AstraZeneca COVID-19 va...   \n",
      "1     COVID-19 in Canada: 'Vaccination passports' a ...   \n",
      "2     Coronavirus variants could fuel Canada's third...   \n",
      "3     Canadian government to extend COVID-19 emergen...   \n",
      "4     Canada: Pfizer is 'extremely committed' to mee...   \n",
      "...                                                 ...   \n",
      "1486                                                      \n",
      "1487                                                      \n",
      "1488                                                      \n",
      "1489                                                      \n",
      "1490                                                      \n",
      "\n",
      "                                                   body sentiment  \n",
      "0                                                        positive  \n",
      "1                                                                  \n",
      "2                                                                  \n",
      "3                                                                  \n",
      "4                                                        positive  \n",
      "...                                                 ...       ...  \n",
      "1486  The problem is the calculations themselves and...  positive  \n",
      "1487  I created the Vaxfact site using references to...            \n",
      "1488  >The information I provided is not wrong\\r\\n\\r...  positive  \n",
      "1489  Basically nothing.\\r\\n\\r\\n>Autoimmunity to the...  positive  \n",
      "1490  In this instance, yourself. Broader, that Vaxf...            \n",
      "\n",
      "[1491 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create pandas dataframe output file\n",
    "df_reddit = pd.read_csv('reddit_vm.csv', encoding=\"utf-8\")\n",
    "df_reddit = df_reddit[['title', 'body', 'sentiment']].fillna('')\n",
    "df_reddit['title'] = df_reddit['title'].replace(to_replace='Comment', value='')\n",
    "\n",
    "print(df_reddit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  title  \\\n",
      "0     Health Canada approves AstraZeneca COVID-19 va...   \n",
      "1     COVID-19 Canada: 'Vaccination passports' near ...   \n",
      "2         Coronavirus variants fuel Canada's third wave   \n",
      "3     Canadian government extend COVID-19 emergency ...   \n",
      "4     Canada: Pfizer 'extremely committed' meeting v...   \n",
      "...                                                 ...   \n",
      "1486                                                      \n",
      "1487                                                      \n",
      "1488                                                      \n",
      "1489                                                      \n",
      "1490                                                      \n",
      "\n",
      "                                                   body sentiment  \n",
      "0                                                        positive  \n",
      "1                                                                  \n",
      "2                                                                  \n",
      "3                                                                  \n",
      "4                                                        positive  \n",
      "...                                                 ...       ...  \n",
      "1486  The problem calculations idea layperson napkin...  positive  \n",
      "1487  created Vaxfact site using references reliable...            \n",
      "1488  >The information provided not wrong You've rep...  positive  \n",
      "1489  Basically nothing. >Autoimmunity central nervo...  positive  \n",
      "1490      In instance, yourself. Broader, Vaxfact site.            \n",
      "\n",
      "[1491 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "df_reddit.body = remove_stop_manual(df_reddit.body)\n",
    "df_reddit.title = remove_stop_manual(df_reddit.title)\n",
    "\n",
    "df_reddit.body = df_reddit.body.apply(remove_stopwords)\n",
    "df_reddit.title = df_reddit.title.apply(remove_stopwords)\n",
    "print(df_reddit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       positive\n",
       "1       negative\n",
       "2       negative\n",
       "3       negative\n",
       "4       positive\n",
       "          ...   \n",
       "1486    positive\n",
       "1487    negative\n",
       "1488    positive\n",
       "1489    positive\n",
       "1490    negative\n",
       "Name: sentiment, Length: 1491, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sentiment = df_reddit.sentiment\n",
    "df_sentiment.replace('', 'negative', inplace=True)\n",
    "df_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_title = df_reddit.title\n",
    "df_title.replace('', np.nan, inplace=True)\n",
    "df_title.to_frame(name=\"text\")\n",
    "df_body = df_reddit.body\n",
    "df_body.to_frame(name=\"text\")\n",
    "df_body.replace('', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Health Canada approves AstraZeneca COVID-19 va...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COVID-19 Canada: 'Vaccination passports' near ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Coronavirus variants fuel Canada's third wave</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Canadian government extend COVID-19 emergency ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Canada: Pfizer 'extremely committed' meeting v...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1486</th>\n",
       "      <td>NaN</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1487</th>\n",
       "      <td>NaN</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1488</th>\n",
       "      <td>NaN</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1489</th>\n",
       "      <td>NaN</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1490</th>\n",
       "      <td>NaN</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1491 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title sentiment\n",
       "0     Health Canada approves AstraZeneca COVID-19 va...  positive\n",
       "1     COVID-19 Canada: 'Vaccination passports' near ...  negative\n",
       "2         Coronavirus variants fuel Canada's third wave  negative\n",
       "3     Canadian government extend COVID-19 emergency ...  negative\n",
       "4     Canada: Pfizer 'extremely committed' meeting v...  positive\n",
       "...                                                 ...       ...\n",
       "1486                                                NaN  positive\n",
       "1487                                                NaN  negative\n",
       "1488                                                NaN  positive\n",
       "1489                                                NaN  positive\n",
       "1490                                                NaN  negative\n",
       "\n",
       "[1491 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_title_sentiment = pd.concat([df_title, df_sentiment], axis=1)\n",
    "df_title_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1486</th>\n",
       "      <td>The problem calculations idea layperson napkin...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1487</th>\n",
       "      <td>created Vaxfact site using references reliable...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1488</th>\n",
       "      <td>&gt;The information provided not wrong You've rep...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1489</th>\n",
       "      <td>Basically nothing. &gt;Autoimmunity central nervo...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1490</th>\n",
       "      <td>In instance, yourself. Broader, Vaxfact site.</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1491 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   body sentiment\n",
       "0                                                   NaN  positive\n",
       "1                                                   NaN  negative\n",
       "2                                                   NaN  negative\n",
       "3                                                   NaN  negative\n",
       "4                                                   NaN  positive\n",
       "...                                                 ...       ...\n",
       "1486  The problem calculations idea layperson napkin...  positive\n",
       "1487  created Vaxfact site using references reliable...  negative\n",
       "1488  >The information provided not wrong You've rep...  positive\n",
       "1489  Basically nothing. >Autoimmunity central nervo...  positive\n",
       "1490      In instance, yourself. Broader, Vaxfact site.  negative\n",
       "\n",
       "[1491 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_body_sentiment = pd.concat([df_body, df_sentiment], axis=1)\n",
    "df_body_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Health Canada approves AstraZeneca COVID-19 va...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COVID-19 Canada: 'Vaccination passports' near ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Coronavirus variants fuel Canada's third wave</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Canadian government extend COVID-19 emergency ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Canada: Pfizer 'extremely committed' meeting v...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>father five unvaccinated children. Am unfit pa...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>Love Them. Protect Them. Never Inject Them.</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>Vaccines Are Just Asping For Trouble</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>Dr. Harper explained presentation cervical can...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>Polio arose US period pesticide use skyrockete...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>450 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title sentiment\n",
       "0    Health Canada approves AstraZeneca COVID-19 va...  positive\n",
       "1    COVID-19 Canada: 'Vaccination passports' near ...  negative\n",
       "2        Coronavirus variants fuel Canada's third wave  negative\n",
       "3    Canadian government extend COVID-19 emergency ...  negative\n",
       "4    Canada: Pfizer 'extremely committed' meeting v...  positive\n",
       "..                                                 ...       ...\n",
       "445  father five unvaccinated children. Am unfit pa...  negative\n",
       "446        Love Them. Protect Them. Never Inject Them.  negative\n",
       "447               Vaccines Are Just Asping For Trouble  negative\n",
       "448  Dr. Harper explained presentation cervical can...  negative\n",
       "449  Polio arose US period pesticide use skyrockete...  negative\n",
       "\n",
       "[450 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_title_clean = df_title_sentiment.dropna().drop_duplicates().reset_index(drop=True)\n",
    "df_title_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Your OP. It's not myth. Only one vaccine conta...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://youtu.be/zBkVCpbNnkU</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Because Anti-Vaxxers no sense</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What mean \"your OP\". fairly new reddit.</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>When say no thimerasol, mean childhood schedul...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1093</th>\n",
       "      <td>The problem calculations idea layperson napkin...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1094</th>\n",
       "      <td>created Vaxfact site using references reliable...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>&gt;The information provided not wrong You've rep...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096</th>\n",
       "      <td>Basically nothing. &gt;Autoimmunity central nervo...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1097</th>\n",
       "      <td>In instance, yourself. Broader, Vaxfact site.</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1098 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   body sentiment\n",
       "0     Your OP. It's not myth. Only one vaccine conta...  negative\n",
       "1                          https://youtu.be/zBkVCpbNnkU  positive\n",
       "2                         Because Anti-Vaxxers no sense  positive\n",
       "3               What mean \"your OP\". fairly new reddit.  negative\n",
       "4     When say no thimerasol, mean childhood schedul...  negative\n",
       "...                                                 ...       ...\n",
       "1093  The problem calculations idea layperson napkin...  positive\n",
       "1094  created Vaxfact site using references reliable...  negative\n",
       "1095  >The information provided not wrong You've rep...  positive\n",
       "1096  Basically nothing. >Autoimmunity central nervo...  positive\n",
       "1097      In instance, yourself. Broader, Vaxfact site.  negative\n",
       "\n",
       "[1098 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_body_clean = df_body_sentiment.dropna().drop_duplicates().reset_index(drop=True)\n",
    "df_body_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corpus = pd.DataFrame(index=range(0, 1524), columns=['text', 'sentiment'], dtype='object')\n",
    "df_corpus_text = pd.concat([df_title_clean.title, df_body_clean.body])\n",
    "df_corpus_sentiment = pd.concat([df_title_clean.sentiment, df_body_clean.sentiment])\n",
    "df_corpus_text = df_corpus_text.to_frame(name='text')\n",
    "df_corpus_text.reset_index(inplace=True)\n",
    "df_corpus_sentiment = df_corpus_sentiment.to_frame(name='sentiment')\n",
    "df_corpus_sentiment.reset_index(inplace=True)\n",
    "df_corpus.text = df_corpus_text.text\n",
    "df_corpus.sentiment = df_corpus_sentiment.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Health Canada approves AstraZeneca COVID-19 va...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COVID-19 Canada: 'Vaccination passports' near ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Coronavirus variants fuel Canada's third wave</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Canadian government extend COVID-19 emergency ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Canada: Pfizer 'extremely committed' meeting v...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment\n",
       "0  Health Canada approves AstraZeneca COVID-19 va...  positive\n",
       "1  COVID-19 Canada: 'Vaccination passports' near ...  negative\n",
       "2      Coronavirus variants fuel Canada's third wave  negative\n",
       "3  Canadian government extend COVID-19 emergency ...  negative\n",
       "4  Canada: Pfizer 'extremely committed' meeting v...  positive"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corpus.text = df_corpus.text.apply(lambda x: text_to_word_list(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df_corpus.text\n",
    "sentiments = df_corpus.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_list = []\n",
    "for i in range(len(texts)):\n",
    "    corpus_list.append(texts[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(list(map(lambda x: 1 if x==\"positive\" else 0, sentiments)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 0, 1, 0])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(corpus_list, y, test_size=0.3, random_state=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1066\n",
      "458\n",
      "1066\n",
      "458\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train))\n",
    "print(len(x_test))\n",
    "print(len(y_train))\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=25000)\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "word_to_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_file_loc = os.path.join(\n",
    "    os.path.expanduser('~'), '.keras/datasets/glove.6B.300d.txt'\n",
    ")\n",
    "word_to_vec_map = read_glove_vector(glove_file_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6307\n",
      "300\n",
      "(6308, 300)\n"
     ]
    }
   ],
   "source": [
    "vocab_len = len(word_to_index)\n",
    "embed_vector_len = word_to_vec_map['moon'].shape[0]\n",
    "emb_matrix = np.zeros((vocab_len + 1, embed_vector_len))\n",
    "print(vocab_len)\n",
    "print(embed_vector_len)\n",
    "print(emb_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word, index in word_to_index.items():\n",
    "    embedding_vec = word_to_vec_map.get(word)\n",
    "    if embedding_vec is not None:\n",
    "        emb_matrix[index, :] = embedding_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Noah\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = Embedding(\n",
    "    input_dim=vocab_len + 1,\n",
    "    output_dim=embed_vector_len,\n",
    "    input_length=max_len,\n",
    "    weights=[emb_matrix],\n",
    "    trainable=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Noah\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 150)]             0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 150, 300)          1892400   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 150, 128)          219648    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 150, 128)          0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 150, 128)          131584    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 150, 128)          0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 2,375,345\n",
      "Trainable params: 482,945\n",
      "Non-trainable params: 1,892,400\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# initalize lstm model \n",
    "model = lstm_model((max_len,))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 150)]             0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 150, 300)          1892400   \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 148, 512)          461312    \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 49, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 47, 256)           393472    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 15, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 13, 256)           196864    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 13, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 4, 256)            0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 3,010,097\n",
      "Trainable params: 1,117,697\n",
      "Non-trainable params: 1,892,400\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "convolution_model = conv_model((max_len,))\n",
    "convolution_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_indices = tokenizer.texts_to_sequences(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1066, 150)\n"
     ]
    }
   ],
   "source": [
    "x_train_indices = pad_sequences(x_train_indices, maxlen=max_len, padding='post')\n",
    "print(x_train_indices.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_indices = tokenizer.texts_to_sequences(x_test)\n",
    "x_test_indices = pad_sequences(x_test_indices, maxlen=max_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Noah\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "adam = tf.keras.optimizers.Adam(learning_rate = 0.0001)\n",
    "convolution_model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-6, patience=10, verbose=2, mode='auto')\n",
    "checkpoint = ModelCheckpoint(filepath=\"best_weights_conv1d.hdf5\", verbose=0, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1066 samples, validate on 458 samples\n",
      "Epoch 1/15\n",
      "1066/1066 [==============================] - 6s 5ms/sample - loss: 0.5531 - acc: 0.8330 - val_loss: 0.5043 - val_acc: 0.8231\n",
      "Epoch 2/15\n",
      "1066/1066 [==============================] - 0s 281us/sample - loss: 0.4689 - acc: 0.8377 - val_loss: 0.4908 - val_acc: 0.8231\n",
      "Epoch 3/15\n",
      "1066/1066 [==============================] - 0s 292us/sample - loss: 0.4358 - acc: 0.8405 - val_loss: 0.4829 - val_acc: 0.8231\n",
      "Epoch 4/15\n",
      "1066/1066 [==============================] - 0s 272us/sample - loss: 0.4092 - acc: 0.8424 - val_loss: 0.4773 - val_acc: 0.8231\n",
      "Epoch 5/15\n",
      "1066/1066 [==============================] - 0s 248us/sample - loss: 0.3836 - acc: 0.8480 - val_loss: 0.4747 - val_acc: 0.8231\n",
      "Epoch 6/15\n",
      "1066/1066 [==============================] - 0s 171us/sample - loss: 0.3542 - acc: 0.8555 - val_loss: 0.4792 - val_acc: 0.8122\n",
      "Epoch 7/15\n",
      "1066/1066 [==============================] - 0s 248us/sample - loss: 0.3198 - acc: 0.8818 - val_loss: 0.4648 - val_acc: 0.8210\n",
      "Epoch 8/15\n",
      "1066/1066 [==============================] - 0s 226us/sample - loss: 0.2790 - acc: 0.9024 - val_loss: 0.4605 - val_acc: 0.8275\n",
      "Epoch 9/15\n",
      "1066/1066 [==============================] - 0s 179us/sample - loss: 0.2349 - acc: 0.9146 - val_loss: 0.5012 - val_acc: 0.7598\n",
      "Epoch 10/15\n",
      "1066/1066 [==============================] - 0s 178us/sample - loss: 0.2177 - acc: 0.9081 - val_loss: 0.4966 - val_acc: 0.8231\n",
      "Epoch 11/15\n",
      "1066/1066 [==============================] - 0s 179us/sample - loss: 0.1742 - acc: 0.9306 - val_loss: 0.4835 - val_acc: 0.7729\n",
      "Epoch 12/15\n",
      "1066/1066 [==============================] - 0s 246us/sample - loss: 0.1409 - acc: 0.9540 - val_loss: 0.4587 - val_acc: 0.8275\n",
      "Epoch 13/15\n",
      "1066/1066 [==============================] - 0s 177us/sample - loss: 0.1056 - acc: 0.9662 - val_loss: 0.4587 - val_acc: 0.8253\n",
      "Epoch 14/15\n",
      "1066/1066 [==============================] - 0s 175us/sample - loss: 0.0795 - acc: 0.9831 - val_loss: 0.4894 - val_acc: 0.8253\n",
      "Epoch 15/15\n",
      "1066/1066 [==============================] - 0s 172us/sample - loss: 0.0578 - acc: 0.9897 - val_loss: 0.4923 - val_acc: 0.8253\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2641a32d688>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Conv1D model\n",
    "convolution_model.fit(x_train_indices, y_train, batch_size=64, callbacks=[monitor, checkpoint], epochs=15, validation_data=(x_test_indices, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "convolution_model.load_weights('best_weights_conv1d.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1066 samples, validate on 458 samples\n",
      "Epoch 1/15\n",
      "1066/1066 [==============================] - 16s 15ms/sample - loss: 0.6858 - acc: 0.8368 - val_loss: 0.6759 - val_acc: 0.8231\n",
      "Epoch 2/15\n",
      "1066/1066 [==============================] - 13s 12ms/sample - loss: 0.6543 - acc: 0.8377 - val_loss: 0.6228 - val_acc: 0.8231\n",
      "Epoch 3/15\n",
      "1066/1066 [==============================] - 13s 12ms/sample - loss: 0.5414 - acc: 0.8377 - val_loss: 0.4979 - val_acc: 0.8231\n",
      "Epoch 4/15\n",
      "1066/1066 [==============================] - 13s 13ms/sample - loss: 0.4646 - acc: 0.8377 - val_loss: 0.4711 - val_acc: 0.8231\n",
      "Epoch 5/15\n",
      "1066/1066 [==============================] - 13s 12ms/sample - loss: 0.4384 - acc: 0.8405 - val_loss: 0.4637 - val_acc: 0.8253\n",
      "Epoch 6/15\n",
      "1066/1066 [==============================] - 13s 12ms/sample - loss: 0.4346 - acc: 0.8433 - val_loss: 0.4653 - val_acc: 0.8231\n",
      "Epoch 7/15\n",
      "1066/1066 [==============================] - 13s 12ms/sample - loss: 0.4334 - acc: 0.8452 - val_loss: 0.4620 - val_acc: 0.8231\n",
      "Epoch 8/15\n",
      "1066/1066 [==============================] - 13s 12ms/sample - loss: 0.4303 - acc: 0.8452 - val_loss: 0.4636 - val_acc: 0.8253\n",
      "Epoch 9/15\n",
      "1066/1066 [==============================] - 13s 12ms/sample - loss: 0.4288 - acc: 0.8462 - val_loss: 0.4638 - val_acc: 0.8210\n",
      "Epoch 10/15\n",
      "1066/1066 [==============================] - 13s 12ms/sample - loss: 0.4268 - acc: 0.8462 - val_loss: 0.4633 - val_acc: 0.8210\n",
      "Epoch 11/15\n",
      "1066/1066 [==============================] - 13s 12ms/sample - loss: 0.4259 - acc: 0.8471 - val_loss: 0.4644 - val_acc: 0.8188\n",
      "Epoch 12/15\n",
      "1066/1066 [==============================] - 13s 12ms/sample - loss: 0.4268 - acc: 0.8471 - val_loss: 0.4629 - val_acc: 0.8231\n",
      "Epoch 13/15\n",
      "1066/1066 [==============================] - 13s 12ms/sample - loss: 0.4276 - acc: 0.8471 - val_loss: 0.4674 - val_acc: 0.8188\n",
      "Epoch 14/15\n",
      "1066/1066 [==============================] - 13s 12ms/sample - loss: 0.4234 - acc: 0.8471 - val_loss: 0.4656 - val_acc: 0.8188\n",
      "Epoch 15/15\n",
      "1066/1066 [==============================] - 14s 13ms/sample - loss: 0.4242 - acc: 0.8480 - val_loss: 0.4700 - val_acc: 0.8188\n"
     ]
    }
   ],
   "source": [
    "# LSTM model\n",
    "adam = tf.keras.optimizers.Adam(learning_rate = 0.0001)\n",
    "model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-6, patience=10, verbose=2, mode='auto')\n",
    "checkpoint = ModelCheckpoint(filepath=\"best_weights_lstm.hdf5\", verbose=0, save_best_only=True)\n",
    "\n",
    "model.fit(x_train_indices, y_train, batch_size=64, callbacks=[monitor, checkpoint], epochs=15, validation_data=(x_test_indices, y_test))\n",
    "\n",
    "model.load_weights('best_weights_lstm.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_test_indices = tokenizer.texts_to_sequences(x_test)\n",
    "# x_test_indices = pad_sequences(x_test_indices, maxlen=max_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "458/458 [==============================] - 5s 12ms/sample - loss: 0.4620 - acc: 0.8231\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4619525408120134, 0.8231441]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test_indices, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "458/458 [==============================] - 0s 133us/sample - loss: 0.4587 - acc: 0.8275\n",
      "Test loss: 0.4586509052322421\n",
      "Test accuracy: 0.8275108933448792\n"
     ]
    }
   ],
   "source": [
    "cnn_score = convolution_model.evaluate(x_test_indices, y_test)\n",
    "print('Test loss: {}'.format(cnn_score[0]))\n",
    "print('Test accuracy: {}'.format(cnn_score[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_predictions = convolution_model.predict(x_test_indices)\n",
    "#print(cnn_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'humans not considered someone making mighty profit created certain dna tampered vaccines '"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = np.random.randint(0, len(x_test))\n",
    "x_test[n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted sentiment is negative\n",
      "correct sentiment is negative\n"
     ]
    }
   ],
   "source": [
    "if cnn_predictions[n] > 0.5:\n",
    "    print('predicted sentiment is positive')\n",
    "else:\n",
    "    print('predicted sentiment is negative')\n",
    "    \n",
    "if y_test[n] == 1:\n",
    "    print('correct sentiment is positive')\n",
    "else:\n",
    "    print('correct sentiment is negative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.11730966]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(cnn_predictions[n])\n",
    "print(y_test[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "convolution_model.save_weights('best_weights_conv1d.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_tokens = tokenizer.texts_to_sequences(corpus_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     predicted sentiment\n",
      "0               negative\n",
      "1               negative\n",
      "2               negative\n",
      "3               negative\n",
      "4               positive\n",
      "...                  ...\n",
      "1519            negative\n",
      "1520            negative\n",
      "1521            negative\n",
      "1522            negative\n",
      "1523            negative\n",
      "\n",
      "[1524 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "data = df_corpus\n",
    "data = predict_sentiments(data, corpus_tokens)\n",
    "# predicted_sentiments will be used for evaluation\n",
    "predicted_sentiments = data.drop(['text', 'sentiment','sentiment score'], axis=1)\n",
    "print(predicted_sentiments)\n",
    "xxx = predicted_sentiments['predicted sentiment'].map(make_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['text', 'sentiment', 'sentiment score', 'predicted sentiment']].to_csv('cnn_prediction.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment score</th>\n",
       "      <th>predicted sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>health canada approves astrazeneca covid - 19 ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.348422</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>covid - 19 canada : vaccination passports near...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.061391</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>coronavirus variants fuel canada third wave</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.024403</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>canadian government extend covid - 19 emergenc...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.101381</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>canada : pfizer extremely committed meeting va...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.725036</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1519</th>\n",
       "      <td>still 100 000 deaths measles every year world ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.018388</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1520</th>\n",
       "      <td>qualifies something toxin ppb even ppm toxins ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.052065</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1521</th>\n",
       "      <td>answer question said cannot cause damage body ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.038383</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1522</th>\n",
       "      <td>yeah long time ago vaccines weren t safe today...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.188827</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523</th>\n",
       "      <td>no one ever hurt mercury vaccine ever</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.106970</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1524 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text sentiment  \\\n",
       "0     health canada approves astrazeneca covid - 19 ...  positive   \n",
       "1     covid - 19 canada : vaccination passports near...  negative   \n",
       "2           coronavirus variants fuel canada third wave  negative   \n",
       "3     canadian government extend covid - 19 emergenc...  negative   \n",
       "4     canada : pfizer extremely committed meeting va...  positive   \n",
       "...                                                 ...       ...   \n",
       "1519  still 100 000 deaths measles every year world ...  negative   \n",
       "1520  qualifies something toxin ppb even ppm toxins ...  negative   \n",
       "1521  answer question said cannot cause damage body ...  negative   \n",
       "1522  yeah long time ago vaccines weren t safe today...  positive   \n",
       "1523             no one ever hurt mercury vaccine ever   negative   \n",
       "\n",
       "      sentiment score predicted sentiment  \n",
       "0            0.348422            negative  \n",
       "1            0.061391            negative  \n",
       "2            0.024403            negative  \n",
       "3            0.101381            negative  \n",
       "4            0.725036            positive  \n",
       "...               ...                 ...  \n",
       "1519         0.018388            negative  \n",
       "1520         0.052065            negative  \n",
       "1521         0.038383            negative  \n",
       "1522         0.188827            negative  \n",
       "1523         0.106970            negative  \n",
       "\n",
       "[1524 rows x 4 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 1 1 0 1 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 1 0 0 0 0 1 0 1 0 0 0\n",
      " 0 1 0 0 0 1 0 0 1 0 0 1 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 1 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 1 0 0 0 1 0 1 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 0 0\n",
      " 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0\n",
      " 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 1 0 0 0 0 1 1 1 0 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Model Evaluation\n",
    "As a classification model, this model will be evaluated on the following metrics: \n",
    " * Accuracy\n",
    " * Precision\n",
    " * Recall\n",
    " * F1 Score\n",
    " * Log Loss\n",
    " * Confusion Matrix\n",
    " * ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [458, 1524]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-80-731ed997a9f2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# change cnn_predictions are ints, we need predicted sentiment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcnn_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxxx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Accuracy: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mf1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'weighted'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m     \u001b[1;31m# Compute accuracy for each possible representation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'multilabel'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m     \"\"\"\n\u001b[1;32m---> 80\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    210\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[1;32m--> 212\u001b[1;33m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[0;32m    213\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [458, 1524]"
     ]
    }
   ],
   "source": [
    "# change cnn_predictions are ints, we need predicted sentiment\n",
    "cnn_score = metrics.accuracy_score(y_test, xxx)\n",
    "print('Accuracy: {}'.format(score))\n",
    "\n",
    "f1 = metrics.f1_score(y_true, pred, average='weighted')\n",
    "print('Averaged F1: {}'.format(f1))\n",
    "\n",
    "#accuracy, precision, recall, f1 score\n",
    "print(metrics.classification_report(y_test, cnn_predictions))\n",
    "\n",
    "#log loss\n",
    "logLoss = metrics.log_loss(y_test, cnn_predictions)\n",
    "print('Log Loss: {}'.format(logLoss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
