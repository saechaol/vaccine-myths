{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noah Venethongkham, 219660117\n",
    "# Ashley Thor, 219334909\n",
    "# Lucas Saechao, 218794239\n",
    "# CSC 180 - Intelligent Systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to\n[nltk_data]     C:\\Users\\ashle\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 162
    }
   ],
   "source": [
    "# matplotlib\n",
    "%matplotlib inline\n",
    "from matplotlib.pyplot import figure, show\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# numpy and pandas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "\n",
    "# scikit learn\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, log_loss\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.utils import column_or_1d\n",
    "import sklearn.feature_extraction.text as sk_text\n",
    "import skimage.transform\n",
    "\n",
    "# natural language toolkit\n",
    "# run pip install nltk\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.test.utils import get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# tensorflow and keras\n",
    "from tensorflow.keras import optimizers, regularizers\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.layers import LSTM, Input, Dense, Activation, Flatten, Dropout, Conv1D, Conv2D, GlobalMaxPooling1D, MaxPooling1D, MaxPooling2D, Embedding\n",
    "#from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# run pip install np_utils\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# python libraries\n",
    "from collections.abc import Sequence\n",
    "import requests\n",
    "import pathlib\n",
    "import shutil\n",
    "import string\n",
    "import json\n",
    "import time\n",
    "import csv\n",
    "import io\n",
    "import os\n",
    "import re\n",
    "\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode text values to dummy variables(i.e. [1,0,0],[0,1,0],[0,0,1] for red,green,blue)\n",
    "def encode_text_dummy(df, name):\n",
    "    dummies = pd.get_dummies(df[name])\n",
    "    for x in dummies.columns:\n",
    "        dummy_name = \"{}-{}\".format(name, x)\n",
    "        df[dummy_name] = dummies[x]\n",
    "    df.drop(name, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# Encode text values to indexes(i.e. [1],[2],[3] for red,green,blue).\n",
    "def encode_text_index(df, name):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df[name] = le.fit_transform(df[name])\n",
    "    return le.classes_\n",
    "\n",
    "\n",
    "# Encode a numeric column as zscores\n",
    "def encode_numeric_zscore(df, name, mean=None, sd=None):\n",
    "    if mean is None:\n",
    "        mean = df[name].mean()\n",
    "    if sd is None:\n",
    "        sd = df[name].std()\n",
    "    df[name] = (df[name] - mean) / sd\n",
    "\n",
    "\n",
    "# Convert all missing values in the specified column to the median\n",
    "def missing_median(df, name):\n",
    "    med = df[name].median()\n",
    "    df[name] = df[name].fillna(med)\n",
    "\n",
    "\n",
    "# Convert all missing values in the specified column to the default\n",
    "def missing_default(df, name, default_value):\n",
    "    df[name] = df[name].fillna(default_value)\n",
    "\n",
    "\n",
    "# Convert a Pandas dataframe to the x,y inputs that TensorFlow needs\n",
    "def to_xy(df, target):\n",
    "    result = []\n",
    "    for x in df.columns:\n",
    "        if x != target:\n",
    "            result.append(x)\n",
    "    # find out the type of the target column. \n",
    "    target_type = df[target].dtypes\n",
    "    target_type = target_type[0] if isinstance(target_type, Sequence) else target_type\n",
    "    # Encode to int for classification, float otherwise. TensorFlow likes 32 bits.\n",
    "    if target_type in (np.int64, np.int32):\n",
    "        # Classification\n",
    "        dummies = pd.get_dummies(df[target])\n",
    "        return df[result].values.astype(np.float32), dummies.values.astype(np.float32)\n",
    "    else:\n",
    "        # Regression\n",
    "        return df[result].values.astype(np.float32), df[target].values.astype(np.float32)\n",
    "\n",
    "# Nicely formatted time string\n",
    "def hms_string(sec_elapsed):\n",
    "    h = int(sec_elapsed / (60 * 60))\n",
    "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
    "    s = sec_elapsed % 60\n",
    "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)\n",
    "\n",
    "\n",
    "# Regression chart.\n",
    "def chart_regression(pred,y,sort=True):\n",
    "    t = pd.DataFrame({'pred' : pred, 'y' : y.flatten()})\n",
    "    if sort:\n",
    "        t.sort_values(by=['y'],inplace=True)\n",
    "    a = plt.plot(t['y'].tolist(),label='expected')\n",
    "    b = plt.plot(t['pred'].tolist(),label='prediction')\n",
    "    plt.ylabel('output')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Remove all rows where the specified column is +/- sd standard deviations\n",
    "def remove_outliers(df, name, sd):\n",
    "    drop_rows = df.index[(np.abs(df[name] - df[name].mean()) >= (sd * df[name].std()))]\n",
    "    df.drop(drop_rows, axis=0, inplace=True)\n",
    "\n",
    "\n",
    "# Encode a column to a range between normalized_low and normalized_high.\n",
    "def encode_numeric_range(df, name, normalized_low=-1, normalized_high=1,\n",
    "                         data_low=None, data_high=None):\n",
    "    if data_low is None:\n",
    "        data_low = min(df[name])\n",
    "        data_high = max(df[name])\n",
    "    df[name] = ((df[name] - data_low) / (data_high - data_low)) \\\n",
    "               * (normalized_high - normalized_low) + normalized_low\n",
    "\n",
    "# Plots a confusion matrix for the model\n",
    "def plot_confusion_matrix(cm, names, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(names))\n",
    "    plt.xticks(tick_marks, names, rotation=45)\n",
    "    plt.yticks(tick_marks, names)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "# Plot an ROC curve\n",
    "def plot_roc(pred, y):\n",
    "    fpr, tpr, thresholds = roc_curve(y, pred)\n",
    "    roc_area_under_curve = auc(fpr, tpr)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label='ROC curve (area = $0.2f)' % roc_area_under_curve)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC)')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show\n",
    " \n",
    "def text_to_word_list(text):\n",
    "    text = str(text)\n",
    "    text = text.lower()\n",
    "    \n",
    "    # clean text by regex\n",
    "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=><]\", \" \", text)\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"cannot \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\",\", \" \", text)\n",
    "    text = re.sub(r\"\\.\", \" \", text)\n",
    "    text = re.sub(r\"!\", \" ! \", text)\n",
    "    text = re.sub(r\"\\/\", \" \", text)\n",
    "    text = re.sub(r\"\\^\", \" ^ \", text)\n",
    "    text = re.sub(r\"\\+\", \" + \", text)\n",
    "    text = re.sub(r\"\\>\", \" \", text)\n",
    "    text = re.sub(r\"\\-\", \" - \", text)\n",
    "    text = re.sub(r\"\\=\", \" = \", text)\n",
    "    text = re.sub(r\"\\'\", \" \", text)\n",
    "    text = re.sub(r\"'\", \" \", text)\n",
    "    text = re.sub(r\"(\\d+)(k)\", \"\\g<1>000\", text)\n",
    "    text = re.sub(r\":\", \" : \", text)\n",
    "    text = re.sub(r\" e g \", \" eg \", text)\n",
    "    text = re.sub(r\" b g \", \" bg \", text)\n",
    "    text = re.sub(r\" u s \", \" american \", text)\n",
    "    text = re.sub(r\"\\0s\", \"0\", text)\n",
    "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
    "    text = re.sub(r\"e - mail\", \"email\", text)\n",
    "    text = re.sub(r\"covid19\", \"covid\", text)\n",
    "    text = re.sub(r\"covid-19\", \"covid\", text)\n",
    "    text = re.sub(r\"covid - 19\", \"covid\", text)\n",
    "    text = re.sub(r\"j k\", \"jk\", text)\n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "    text = re.sub('<.*?>', '', text)\n",
    "    text = text.split()\n",
    "    return text\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    stopwords_list = stopwords.words('english')\n",
    "    whitelist = [\"n't\", \"not\", \"no\"]\n",
    "    words = text.split()\n",
    "    words_clean = [word for word in words if (word not in stopwords_list or word in whitelist) and len(word) > 1]\n",
    "    return \" \".join(words_clean)\n",
    "    \n",
    "def read_glove_vector(glove_vec):\n",
    "    with open(glove_vec, 'r', encoding='utf-8') as f:\n",
    "        words = set()\n",
    "        word_to_vec_map = {}\n",
    "        for line in f:\n",
    "            w_line = line.split()\n",
    "            current_word = w_line[0]\n",
    "            word_to_vec_map[current_word] = np.array(w_line[1:], dtype=np.float64)\n",
    "    return word_to_vec_map\n",
    "    \n",
    "def lstm_model(input_shape):\n",
    "    x_indices = Input(input_shape)\n",
    "    embeddings = embedding_layer(x_indices)\n",
    "    x = LSTM(128, return_sequences=True)(embeddings)\n",
    "    x = Dropout(0.6)(x)\n",
    "    x = LSTM(128, return_sequences=True)(x)\n",
    "    x = Dropout(0.6)(x)\n",
    "    x = LSTM(128)(x)\n",
    "    x = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=x_indices, outputs=x)\n",
    "    return model\n",
    "\n",
    "def conv_model(input_shape):\n",
    "    x_indices = Input(input_shape)\n",
    "    embeddings = embedding_layer(x_indices)\n",
    "    x = Conv1D(512, 3, activation='relu')(embeddings)\n",
    "    x = MaxPooling1D(3)(x)\n",
    "    x = Conv1D(256, 3, activation='relu')(x)\n",
    "    x = MaxPooling1D(3)(x)\n",
    "    x = Conv1D(256, 3, activation='relu')(x)\n",
    "    x = Dropout(0.8)(x)\n",
    "    x = MaxPooling1D(3)(x)\n",
    "    x = GlobalMaxPooling1D()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=x_indices, outputs=x)\n",
    "    return model\n",
    "    \n",
    "def predict_sentiments(data, corpus):\n",
    "    data['sentiment score'] = 0\n",
    "    corpus = pad_sequences(corpus, maxlen=max_len, padding='post')\n",
    "    pred = model.predict(corpus)\n",
    "    data['sentiment score'] = pred\n",
    "    pred_sentiment = np.array(list(map(lambda x: 'positive' if x > 0.5 else 'negative', pred)))\n",
    "    data['predicted sentiment'] = 0\n",
    "    data['predicted sentiment'] = pred_sentiment\n",
    "    return data\n",
    "    \n",
    "# Beep if on a windows machine\n",
    "if os.name == 'nt':\n",
    "    def ding():\n",
    "        winsound.Beep(2000, 300)\n",
    "        winsound.Beep(2000, 300)\n",
    "        winsound.Beep(2000, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                                                  title  \\\n0     Health Canada approves AstraZeneca COVID-19 va...   \n1     COVID-19 in Canada: 'Vaccination passports' a ...   \n2     Coronavirus variants could fuel Canada's third...   \n3     Canadian government to extend COVID-19 emergen...   \n4     Canada: Pfizer is 'extremely committed' to mee...   \n...                                                 ...   \n1486                                                      \n1487                                                      \n1488                                                      \n1489                                                      \n1490                                                      \n\n                                                   body sentiment  \n0                                                        positive  \n1                                                                  \n2                                                                  \n3                                                                  \n4                                                        positive  \n...                                                 ...       ...  \n1486  The problem is the calculations themselves and...  positive  \n1487  I created the Vaxfact site using references to...            \n1488  >The information I provided is not wrong\\r\\n\\r...  positive  \n1489  Basically nothing.\\r\\n\\r\\n>Autoimmunity to the...  positive  \n1490  In this instance, yourself. Broader, that Vaxf...            \n\n[1491 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create pandas dataframe output file\n",
    "df_reddit = pd.read_csv('reddit_vm.csv', encoding=\"utf-8\")\n",
    "df_reddit = df_reddit[['title', 'body', 'sentiment']].fillna('')\n",
    "df_reddit['title'] = df_reddit['title'].replace(to_replace='Comment', value='')\n",
    "\n",
    "print(df_reddit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                                                  title  \\\n0     Health Canada approves AstraZeneca COVID-19 va...   \n1     COVID-19 Canada: 'Vaccination passports' near ...   \n2     Coronavirus variants could fuel Canada's third...   \n3     Canadian government extend COVID-19 emergency ...   \n4     Canada: Pfizer 'extremely committed' meeting v...   \n...                                                 ...   \n1486                                                      \n1487                                                      \n1488                                                      \n1489                                                      \n1490                                                      \n\n                                                   body sentiment  \n0                                                        positive  \n1                                                                  \n2                                                                  \n3                                                                  \n4                                                        positive  \n...                                                 ...       ...  \n1486  The problem calculations idea layperson napkin...  positive  \n1487  created Vaxfact site using references reliable...            \n1488  >The information provided not wrong You've rep...  positive  \n1489  Basically nothing. >Autoimmunity central nervo...  positive  \n1490      In instance, yourself. Broader, Vaxfact site.            \n\n[1491 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "df_reddit.body = df_reddit.body.apply(remove_stopwords)\n",
    "df_reddit.title = df_reddit.title.apply(remove_stopwords)\n",
    "print(df_reddit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0       positive\n",
       "1       negative\n",
       "2       negative\n",
       "3       negative\n",
       "4       positive\n",
       "          ...   \n",
       "1486    positive\n",
       "1487    negative\n",
       "1488    positive\n",
       "1489    positive\n",
       "1490    negative\n",
       "Name: sentiment, Length: 1491, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 166
    }
   ],
   "source": [
    "df_sentiment = df_reddit.sentiment\n",
    "df_sentiment.replace('', 'negative', inplace=True)\n",
    "df_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_title = df_reddit.title\n",
    "df_title.replace('', np.nan, inplace=True)\n",
    "df_title.to_frame(name=\"text\")\n",
    "df_body = df_reddit.body\n",
    "df_body.to_frame(name=\"text\")\n",
    "df_body.replace('', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                  title sentiment\n",
       "0     Health Canada approves AstraZeneca COVID-19 va...  positive\n",
       "1     COVID-19 Canada: 'Vaccination passports' near ...  negative\n",
       "2     Coronavirus variants could fuel Canada's third...  negative\n",
       "3     Canadian government extend COVID-19 emergency ...  negative\n",
       "4     Canada: Pfizer 'extremely committed' meeting v...  positive\n",
       "...                                                 ...       ...\n",
       "1486                                                NaN  positive\n",
       "1487                                                NaN  negative\n",
       "1488                                                NaN  positive\n",
       "1489                                                NaN  positive\n",
       "1490                                                NaN  negative\n",
       "\n",
       "[1491 rows x 2 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Health Canada approves AstraZeneca COVID-19 va...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>COVID-19 Canada: 'Vaccination passports' near ...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Coronavirus variants could fuel Canada's third...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Canadian government extend COVID-19 emergency ...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Canada: Pfizer 'extremely committed' meeting v...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1486</th>\n      <td>NaN</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>1487</th>\n      <td>NaN</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>1488</th>\n      <td>NaN</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>1489</th>\n      <td>NaN</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>1490</th>\n      <td>NaN</td>\n      <td>negative</td>\n    </tr>\n  </tbody>\n</table>\n<p>1491 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 168
    }
   ],
   "source": [
    "df_title_sentiment = pd.concat([df_title, df_sentiment], axis=1)\n",
    "df_title_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                   body sentiment\n",
       "0                                                   NaN  positive\n",
       "1                                                   NaN  negative\n",
       "2                                                   NaN  negative\n",
       "3                                                   NaN  negative\n",
       "4                                                   NaN  positive\n",
       "...                                                 ...       ...\n",
       "1486  The problem calculations idea layperson napkin...  positive\n",
       "1487  created Vaxfact site using references reliable...  negative\n",
       "1488  >The information provided not wrong You've rep...  positive\n",
       "1489  Basically nothing. >Autoimmunity central nervo...  positive\n",
       "1490      In instance, yourself. Broader, Vaxfact site.  negative\n",
       "\n",
       "[1491 rows x 2 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>body</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>NaN</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>NaN</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>NaN</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>NaN</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>NaN</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1486</th>\n      <td>The problem calculations idea layperson napkin...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>1487</th>\n      <td>created Vaxfact site using references reliable...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>1488</th>\n      <td>&gt;The information provided not wrong You've rep...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>1489</th>\n      <td>Basically nothing. &gt;Autoimmunity central nervo...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>1490</th>\n      <td>In instance, yourself. Broader, Vaxfact site.</td>\n      <td>negative</td>\n    </tr>\n  </tbody>\n</table>\n<p>1491 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 169
    }
   ],
   "source": [
    "df_body_sentiment = pd.concat([df_body, df_sentiment], axis=1)\n",
    "df_body_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                 title sentiment\n",
       "0    Health Canada approves AstraZeneca COVID-19 va...  positive\n",
       "1    COVID-19 Canada: 'Vaccination passports' near ...  negative\n",
       "2    Coronavirus variants could fuel Canada's third...  negative\n",
       "3    Canadian government extend COVID-19 emergency ...  negative\n",
       "4    Canada: Pfizer 'extremely committed' meeting v...  positive\n",
       "..                                                 ...       ...\n",
       "445  father five unvaccinated children. Am unfit pa...  negative\n",
       "446        Love Them. Protect Them. Never Inject Them.  negative\n",
       "447               Vaccines Are Just Asping For Trouble  negative\n",
       "448  Dr. Harper explained presentation cervical can...  negative\n",
       "449  Polio arose US period pesticide use skyrockete...  negative\n",
       "\n",
       "[450 rows x 2 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Health Canada approves AstraZeneca COVID-19 va...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>COVID-19 Canada: 'Vaccination passports' near ...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Coronavirus variants could fuel Canada's third...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Canadian government extend COVID-19 emergency ...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Canada: Pfizer 'extremely committed' meeting v...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>445</th>\n      <td>father five unvaccinated children. Am unfit pa...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>446</th>\n      <td>Love Them. Protect Them. Never Inject Them.</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>447</th>\n      <td>Vaccines Are Just Asping For Trouble</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>448</th>\n      <td>Dr. Harper explained presentation cervical can...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>449</th>\n      <td>Polio arose US period pesticide use skyrockete...</td>\n      <td>negative</td>\n    </tr>\n  </tbody>\n</table>\n<p>450 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 170
    }
   ],
   "source": [
    "df_title_clean = df_title_sentiment.dropna().drop_duplicates().reset_index(drop=True)\n",
    "df_title_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                   body sentiment\n",
       "0     Your OP. It's not myth. Only one vaccine conta...  negative\n",
       "1                          https://youtu.be/zBkVCpbNnkU  positive\n",
       "2                         Because Anti-Vaxxers no sense  positive\n",
       "3               What mean \"your OP\". fairly new reddit.  negative\n",
       "4     When say there's no thimerasol, mean childhood...  negative\n",
       "...                                                 ...       ...\n",
       "1093  The problem calculations idea layperson napkin...  positive\n",
       "1094  created Vaxfact site using references reliable...  negative\n",
       "1095  >The information provided not wrong You've rep...  positive\n",
       "1096  Basically nothing. >Autoimmunity central nervo...  positive\n",
       "1097      In instance, yourself. Broader, Vaxfact site.  negative\n",
       "\n",
       "[1098 rows x 2 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>body</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Your OP. It's not myth. Only one vaccine conta...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>https://youtu.be/zBkVCpbNnkU</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Because Anti-Vaxxers no sense</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>What mean \"your OP\". fairly new reddit.</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>When say there's no thimerasol, mean childhood...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1093</th>\n      <td>The problem calculations idea layperson napkin...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>1094</th>\n      <td>created Vaxfact site using references reliable...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>1095</th>\n      <td>&gt;The information provided not wrong You've rep...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>1096</th>\n      <td>Basically nothing. &gt;Autoimmunity central nervo...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>1097</th>\n      <td>In instance, yourself. Broader, Vaxfact site.</td>\n      <td>negative</td>\n    </tr>\n  </tbody>\n</table>\n<p>1098 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 171
    }
   ],
   "source": [
    "df_body_clean = df_body_sentiment.dropna().drop_duplicates().reset_index(drop=True)\n",
    "df_body_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corpus = pd.DataFrame(index=range(0, 1524), columns=['text', 'sentiment'], dtype='object')\n",
    "df_corpus_text = pd.concat([df_title_clean.title, df_body_clean.body])\n",
    "df_corpus_sentiment = pd.concat([df_title_clean.sentiment, df_body_clean.sentiment])\n",
    "df_corpus_text = df_corpus_text.to_frame(name='text')\n",
    "df_corpus_text.reset_index(inplace=True)\n",
    "df_corpus_sentiment = df_corpus_sentiment.to_frame(name='sentiment')\n",
    "df_corpus_sentiment.reset_index(inplace=True)\n",
    "df_corpus.text = df_corpus_text.text\n",
    "df_corpus.sentiment = df_corpus_sentiment.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                text sentiment\n",
       "0  Health Canada approves AstraZeneca COVID-19 va...  positive\n",
       "1  COVID-19 Canada: 'Vaccination passports' near ...  negative\n",
       "2  Coronavirus variants could fuel Canada's third...  negative\n",
       "3  Canadian government extend COVID-19 emergency ...  negative\n",
       "4  Canada: Pfizer 'extremely committed' meeting v...  positive"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Health Canada approves AstraZeneca COVID-19 va...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>COVID-19 Canada: 'Vaccination passports' near ...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Coronavirus variants could fuel Canada's third...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Canadian government extend COVID-19 emergency ...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Canada: Pfizer 'extremely committed' meeting v...</td>\n      <td>positive</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 173
    }
   ],
   "source": [
    "df_corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df_corpus.text\n",
    "sentiments = df_corpus.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_list = []\n",
    "for i in range(len(texts)):\n",
    "    corpus_list.append(texts[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(list(map(lambda x: 1 if x==\"positive\" else 0, sentiments)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 0, 1, 0])"
      ]
     },
     "metadata": {},
     "execution_count": 177
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(corpus_list, y, test_size=0.3, random_state=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1066\n458\n1066\n458\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train))\n",
    "print(len(x_test))\n",
    "print(len(y_train))\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=25000)\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "word_to_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_file_loc = os.path.join(\n",
    "    os.path.expanduser('~'), '.keras/datasets/glove.6B.300d.txt'\n",
    ")\n",
    "word_to_vec_map = read_glove_vector(glove_file_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6963\n300\n(6964, 300)\n"
     ]
    }
   ],
   "source": [
    "vocab_len = len(word_to_index)\n",
    "embed_vector_len = word_to_vec_map['moon'].shape[0]\n",
    "emb_matrix = np.zeros((vocab_len + 1, embed_vector_len))\n",
    "print(vocab_len)\n",
    "print(embed_vector_len)\n",
    "print(emb_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word, index in word_to_index.items():\n",
    "    embedding_vec = word_to_vec_map.get(word)\n",
    "    if embedding_vec is not None:\n",
    "        emb_matrix[index, :] = embedding_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(\n",
    "    input_dim=vocab_len + 1,\n",
    "    output_dim=embed_vector_len,\n",
    "    input_length=max_len,\n",
    "    weights=[emb_matrix],\n",
    "    trainable=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model_8\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_9 (InputLayer)         [(None, 150)]             0         \n_________________________________________________________________\nembedding_4 (Embedding)      (None, 150, 300)          2089200   \n_________________________________________________________________\nlstm_12 (LSTM)               (None, 150, 128)          219648    \n_________________________________________________________________\ndropout_12 (Dropout)         (None, 150, 128)          0         \n_________________________________________________________________\nlstm_13 (LSTM)               (None, 150, 128)          131584    \n_________________________________________________________________\ndropout_13 (Dropout)         (None, 150, 128)          0         \n_________________________________________________________________\nlstm_14 (LSTM)               (None, 128)               131584    \n_________________________________________________________________\ndense_12 (Dense)             (None, 1)                 129       \n=================================================================\nTotal params: 2,572,145\nTrainable params: 482,945\nNon-trainable params: 2,089,200\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = lstm_model((max_len,))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model_9\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_10 (InputLayer)        [(None, 150)]             0         \n_________________________________________________________________\nembedding_4 (Embedding)      (None, 150, 300)          2089200   \n_________________________________________________________________\nconv1d_12 (Conv1D)           (None, 148, 512)          461312    \n_________________________________________________________________\nmax_pooling1d_12 (MaxPooling (None, 49, 512)           0         \n_________________________________________________________________\nconv1d_13 (Conv1D)           (None, 47, 256)           393472    \n_________________________________________________________________\nmax_pooling1d_13 (MaxPooling (None, 15, 256)           0         \n_________________________________________________________________\nconv1d_14 (Conv1D)           (None, 13, 256)           196864    \n_________________________________________________________________\ndropout_14 (Dropout)         (None, 13, 256)           0         \n_________________________________________________________________\nmax_pooling1d_14 (MaxPooling (None, 4, 256)            0         \n_________________________________________________________________\nglobal_max_pooling1d_4 (Glob (None, 256)               0         \n_________________________________________________________________\ndense_13 (Dense)             (None, 256)               65792     \n_________________________________________________________________\ndense_14 (Dense)             (None, 1)                 257       \n=================================================================\nTotal params: 3,206,897\nTrainable params: 1,117,697\nNon-trainable params: 2,089,200\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "convolution_model = conv_model((max_len,))\n",
    "convolution_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_indices = tokenizer.texts_to_sequences(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(1066, 150)\n"
     ]
    }
   ],
   "source": [
    "x_train_indices = pad_sequences(x_train_indices, maxlen=max_len, padding='post')\n",
    "print(x_train_indices.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_indices = tokenizer.texts_to_sequences(x_test)\n",
    "x_test_indices = pad_sequences(x_test_indices, maxlen=max_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = tf.keras.optimizers.Adam(learning_rate = 0.0001)\n",
    "convolution_model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-6, patience=10, verbose=2, mode='auto')\n",
    "checkpoint = ModelCheckpoint(filepath=\"best_weights_conv1d.hdf5\", verbose=0, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train on 1066 samples, validate on 458 samples\n",
      "Epoch 1/15\n",
      "1066/1066 [==============================] - 2s 2ms/sample - loss: 0.6056 - acc: 0.7561 - val_loss: 0.5676 - val_acc: 0.8253\n",
      "Epoch 2/15\n",
      "1066/1066 [==============================] - 0s 347us/sample - loss: 0.5174 - acc: 0.8340 - val_loss: 0.5179 - val_acc: 0.8253\n",
      "Epoch 3/15\n",
      "1066/1066 [==============================] - 0s 224us/sample - loss: 0.4976 - acc: 0.8321 - val_loss: 0.5235 - val_acc: 0.8144\n",
      "Epoch 4/15\n",
      "1066/1066 [==============================] - 0s 275us/sample - loss: 0.4697 - acc: 0.8377 - val_loss: 0.5110 - val_acc: 0.8253\n",
      "Epoch 5/15\n",
      "1066/1066 [==============================] - 0s 272us/sample - loss: 0.4463 - acc: 0.8396 - val_loss: 0.4872 - val_acc: 0.8253\n",
      "Epoch 6/15\n",
      "1066/1066 [==============================] - 0s 227us/sample - loss: 0.4353 - acc: 0.8368 - val_loss: 0.4891 - val_acc: 0.8253\n",
      "Epoch 7/15\n",
      "1066/1066 [==============================] - 0s 230us/sample - loss: 0.4172 - acc: 0.8443 - val_loss: 0.5042 - val_acc: 0.8253\n",
      "Epoch 8/15\n",
      "1066/1066 [==============================] - 0s 244us/sample - loss: 0.3962 - acc: 0.8443 - val_loss: 0.5029 - val_acc: 0.8231\n",
      "Epoch 9/15\n",
      "1066/1066 [==============================] - 0s 240us/sample - loss: 0.3736 - acc: 0.8565 - val_loss: 0.4907 - val_acc: 0.8253\n",
      "Epoch 10/15\n",
      "1066/1066 [==============================] - 0s 288us/sample - loss: 0.3641 - acc: 0.8602 - val_loss: 0.4769 - val_acc: 0.8253\n",
      "Epoch 11/15\n",
      "1066/1066 [==============================] - 0s 227us/sample - loss: 0.3552 - acc: 0.8583 - val_loss: 0.5020 - val_acc: 0.8231\n",
      "Epoch 12/15\n",
      "1066/1066 [==============================] - 0s 231us/sample - loss: 0.3493 - acc: 0.8630 - val_loss: 0.4851 - val_acc: 0.8275\n",
      "Epoch 13/15\n",
      "1066/1066 [==============================] - 0s 233us/sample - loss: 0.3168 - acc: 0.8734 - val_loss: 0.4891 - val_acc: 0.8210\n",
      "Epoch 14/15\n",
      "1066/1066 [==============================] - 0s 281us/sample - loss: 0.3030 - acc: 0.8809 - val_loss: 0.4724 - val_acc: 0.8231\n",
      "Epoch 15/15\n",
      "1066/1066 [==============================] - 0s 231us/sample - loss: 0.2676 - acc: 0.8921 - val_loss: 0.4930 - val_acc: 0.8210\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x19217e1e488>"
      ]
     },
     "metadata": {},
     "execution_count": 193
    }
   ],
   "source": [
    "# Conv1D model\n",
    "convolution_model.fit(x_train_indices, y_train, batch_size=64, callbacks=[monitor, checkpoint], epochs=15, validation_data=(x_test_indices, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "convolution_model.load_weights('best_weights_conv1d.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train on 1066 samples, validate on 458 samples\n",
      "Epoch 1/15\n",
      "1066/1066 [==============================] - 15s 15ms/sample - loss: 0.6843 - acc: 0.8340 - val_loss: 0.6741 - val_acc: 0.8253\n",
      "Epoch 2/15\n",
      "1066/1066 [==============================] - 13s 12ms/sample - loss: 0.6520 - acc: 0.8377 - val_loss: 0.6202 - val_acc: 0.8253\n",
      "Epoch 3/15\n",
      "1066/1066 [==============================] - 13s 12ms/sample - loss: 0.5346 - acc: 0.8377 - val_loss: 0.4937 - val_acc: 0.8253\n",
      "Epoch 4/15\n",
      "1066/1066 [==============================] - 14s 13ms/sample - loss: 0.4576 - acc: 0.8377 - val_loss: 0.4618 - val_acc: 0.8253\n",
      "Epoch 5/15\n",
      "1066/1066 [==============================] - 13s 12ms/sample - loss: 0.4376 - acc: 0.8386 - val_loss: 0.4626 - val_acc: 0.8275\n",
      "Epoch 6/15\n",
      "1066/1066 [==============================] - 13s 12ms/sample - loss: 0.4356 - acc: 0.8424 - val_loss: 0.4568 - val_acc: 0.8319\n",
      "Epoch 7/15\n",
      " 384/1066 [=========>....................] - ETA: 6s - loss: 0.4556 - acc: 0.8307"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-195-14dbcd55f2e3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mcheckpoint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"best_weights_lstm.hdf5\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train_indices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test_indices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'best_weights_lstm.hdf5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    778\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m           \u001b[0mvalidation_freq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m           steps_name='steps_per_epoch')\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m         \u001b[1;31m# Get outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 363\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    364\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3292\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# LSTM model\n",
    "adam = tf.keras.optimizers.Adam(learning_rate = 0.0001)\n",
    "model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-6, patience=10, verbose=2, mode='auto')\n",
    "checkpoint = ModelCheckpoint(filepath=\"best_weights_lstm.hdf5\", verbose=0, save_best_only=True)\n",
    "\n",
    "model.fit(x_train_indices, y_train, batch_size=64, callbacks=[monitor, checkpoint], epochs=15, validation_data=(x_test_indices, y_test))\n",
    "\n",
    "model.load_weights('best_weights_lstm.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_test_indices = tokenizer.texts_to_sequences(x_test)\n",
    "# x_test_indices = pad_sequences(x_test_indices, maxlen=max_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "458/458 [==============================] - 5s 11ms/sample - loss: 0.4560 - acc: 0.8253\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0.4560497041352451, 0.8253275]"
      ]
     },
     "metadata": {},
     "execution_count": 150
    }
   ],
   "source": [
    "model.evaluate(x_test_indices, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "458/458 [==============================] - 0s 203us/sample - loss: 0.4360 - acc: 0.8122\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0.4360146106070306, 0.8122271]"
      ]
     },
     "metadata": {},
     "execution_count": 151
    }
   ],
   "source": [
    "convolution_model.evaluate(x_test_indices, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = convolution_model.predict(x_test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'How manufacturing vaccine pollute? There isn’t anything burned'"
      ]
     },
     "metadata": {},
     "execution_count": 153
    }
   ],
   "source": [
    "n = np.random.randint(0, len(x_test))\n",
    "x_test[n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "predicted sentiment is negative\ncorrect sentiment is negative\n"
     ]
    }
   ],
   "source": [
    "if predictions[n] > 0.5:\n",
    "    print('predicted sentiment is positive')\n",
    "else:\n",
    "    print('predicted sentiment is negative')\n",
    "    \n",
    "if y_test[n] == 1:\n",
    "    print('correct sentiment is positive')\n",
    "else:\n",
    "    print('correct sentiment is negative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0.17808822]\n0\n"
     ]
    }
   ],
   "source": [
    "print(predictions[n])\n",
    "print(y_test[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "convolution_model.save_weights('best_weights_conv1d.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_tokens = tokenizer.texts_to_sequences(corpus_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_corpus\n",
    "data = predict_sentiments(data, corpus_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['text', 'sentiment', 'sentiment score', 'predicted sentiment']].to_csv('prediction.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                   text sentiment  \\\n",
       "0     Health Canada approves AstraZeneca COVID-19 va...  positive   \n",
       "1     COVID-19 Canada: 'Vaccination passports' near ...  negative   \n",
       "2     Coronavirus variants could fuel Canada's third...  negative   \n",
       "3     Canadian government extend COVID-19 emergency ...  negative   \n",
       "4     Canada: Pfizer 'extremely committed' meeting v...  positive   \n",
       "...                                                 ...       ...   \n",
       "1519  There still 100,000 deaths measles every year ...  negative   \n",
       "1520  What qualifies something toxin? What ppb even ...  negative   \n",
       "1521  You answer question. You said can't cause dama...  negative   \n",
       "1522  Yeah, long time ago, vaccines weren’t safe tod...  positive   \n",
       "1523          So no one ever hurt mercury vaccine ever?  negative   \n",
       "\n",
       "      sentiment score predicted sentiment  \n",
       "0            0.160525            negative  \n",
       "1            0.160530            negative  \n",
       "2            0.160525            negative  \n",
       "3            0.160525            negative  \n",
       "4            0.160523            negative  \n",
       "...               ...                 ...  \n",
       "1519         0.160531            negative  \n",
       "1520         0.160524            negative  \n",
       "1521         0.160535            negative  \n",
       "1522         0.160523            negative  \n",
       "1523         0.160524            negative  \n",
       "\n",
       "[1524 rows x 4 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>sentiment</th>\n      <th>sentiment score</th>\n      <th>predicted sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Health Canada approves AstraZeneca COVID-19 va...</td>\n      <td>positive</td>\n      <td>0.160525</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>COVID-19 Canada: 'Vaccination passports' near ...</td>\n      <td>negative</td>\n      <td>0.160530</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Coronavirus variants could fuel Canada's third...</td>\n      <td>negative</td>\n      <td>0.160525</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Canadian government extend COVID-19 emergency ...</td>\n      <td>negative</td>\n      <td>0.160525</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Canada: Pfizer 'extremely committed' meeting v...</td>\n      <td>positive</td>\n      <td>0.160523</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1519</th>\n      <td>There still 100,000 deaths measles every year ...</td>\n      <td>negative</td>\n      <td>0.160531</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>1520</th>\n      <td>What qualifies something toxin? What ppb even ...</td>\n      <td>negative</td>\n      <td>0.160524</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>1521</th>\n      <td>You answer question. You said can't cause dama...</td>\n      <td>negative</td>\n      <td>0.160535</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>1522</th>\n      <td>Yeah, long time ago, vaccines weren’t safe tod...</td>\n      <td>positive</td>\n      <td>0.160523</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>1523</th>\n      <td>So no one ever hurt mercury vaccine ever?</td>\n      <td>negative</td>\n      <td>0.160524</td>\n      <td>negative</td>\n    </tr>\n  </tbody>\n</table>\n<p>1524 rows × 4 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 160
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python376jvsc74a57bd0f6d5cac9967d36a68534a233eb03728be3b97600d649ddf8798158979807cedd",
   "display_name": "Python 3.7.6 64-bit (conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}