{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noah Venethongkham, 219660117\n",
    "# Ashley Thor, 219334909\n",
    "# Lucas Saechao, 218794239\n",
    "# CSC 180 - Intelligent Systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\19165\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# matplotlib\n",
    "%matplotlib inline\n",
    "from matplotlib.pyplot import figure, show\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# numpy and pandas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "\n",
    "# scikit learn\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, log_loss\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.utils import column_or_1d\n",
    "import sklearn.feature_extraction.text as sk_text\n",
    "import skimage.transform\n",
    "\n",
    "# natural language toolkit\n",
    "# run pip install nltk\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.test.utils import get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# tensorflow and keras\n",
    "from tensorflow.keras import optimizers, regularizers\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.layers import LSTM, Dense, Activation, Flatten, Dropout, Conv2D, MaxPooling2D, Embedding\n",
    "#from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# run pip install np_utils\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# python libraries\n",
    "from collections.abc import Sequence\n",
    "import requests\n",
    "import pathlib\n",
    "import shutil\n",
    "import string\n",
    "import json\n",
    "import time\n",
    "import csv\n",
    "import io\n",
    "import os\n",
    "import re\n",
    "\n",
    "# if OS is windows, import chime\n",
    "if os.name == 'nt':\n",
    "    import winsound\n",
    "    \n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode text values to dummy variables(i.e. [1,0,0],[0,1,0],[0,0,1] for red,green,blue)\n",
    "def encode_text_dummy(df, name):\n",
    "    dummies = pd.get_dummies(df[name])\n",
    "    for x in dummies.columns:\n",
    "        dummy_name = \"{}-{}\".format(name, x)\n",
    "        df[dummy_name] = dummies[x]\n",
    "    df.drop(name, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# Encode text values to indexes(i.e. [1],[2],[3] for red,green,blue).\n",
    "def encode_text_index(df, name):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df[name] = le.fit_transform(df[name])\n",
    "    return le.classes_\n",
    "\n",
    "\n",
    "# Encode a numeric column as zscores\n",
    "def encode_numeric_zscore(df, name, mean=None, sd=None):\n",
    "    if mean is None:\n",
    "        mean = df[name].mean()\n",
    "    if sd is None:\n",
    "        sd = df[name].std()\n",
    "    df[name] = (df[name] - mean) / sd\n",
    "\n",
    "\n",
    "# Convert all missing values in the specified column to the median\n",
    "def missing_median(df, name):\n",
    "    med = df[name].median()\n",
    "    df[name] = df[name].fillna(med)\n",
    "\n",
    "\n",
    "# Convert all missing values in the specified column to the default\n",
    "def missing_default(df, name, default_value):\n",
    "    df[name] = df[name].fillna(default_value)\n",
    "\n",
    "\n",
    "# Convert a Pandas dataframe to the x,y inputs that TensorFlow needs\n",
    "def to_xy(df, target):\n",
    "    result = []\n",
    "    for x in df.columns:\n",
    "        if x != target:\n",
    "            result.append(x)\n",
    "    # find out the type of the target column. \n",
    "    target_type = df[target].dtypes\n",
    "    target_type = target_type[0] if isinstance(target_type, Sequence) else target_type\n",
    "    # Encode to int for classification, float otherwise. TensorFlow likes 32 bits.\n",
    "    if target_type in (np.int64, np.int32):\n",
    "        # Classification\n",
    "        dummies = pd.get_dummies(df[target])\n",
    "        return df[result].values.astype(np.float32), dummies.values.astype(np.float32)\n",
    "    else:\n",
    "        # Regression\n",
    "        return df[result].values.astype(np.float32), df[target].values.astype(np.float32)\n",
    "\n",
    "# Nicely formatted time string\n",
    "def hms_string(sec_elapsed):\n",
    "    h = int(sec_elapsed / (60 * 60))\n",
    "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
    "    s = sec_elapsed % 60\n",
    "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)\n",
    "\n",
    "\n",
    "# Regression chart.\n",
    "def chart_regression(pred,y,sort=True):\n",
    "    t = pd.DataFrame({'pred' : pred, 'y' : y.flatten()})\n",
    "    if sort:\n",
    "        t.sort_values(by=['y'],inplace=True)\n",
    "    a = plt.plot(t['y'].tolist(),label='expected')\n",
    "    b = plt.plot(t['pred'].tolist(),label='prediction')\n",
    "    plt.ylabel('output')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Remove all rows where the specified column is +/- sd standard deviations\n",
    "def remove_outliers(df, name, sd):\n",
    "    drop_rows = df.index[(np.abs(df[name] - df[name].mean()) >= (sd * df[name].std()))]\n",
    "    df.drop(drop_rows, axis=0, inplace=True)\n",
    "\n",
    "\n",
    "# Encode a column to a range between normalized_low and normalized_high.\n",
    "def encode_numeric_range(df, name, normalized_low=-1, normalized_high=1,\n",
    "                         data_low=None, data_high=None):\n",
    "    if data_low is None:\n",
    "        data_low = min(df[name])\n",
    "        data_high = max(df[name])\n",
    "    df[name] = ((df[name] - data_low) / (data_high - data_low)) \\\n",
    "               * (normalized_high - normalized_low) + normalized_low\n",
    "\n",
    "# Plots a confusion matrix for the model\n",
    "def plot_confusion_matrix(cm, names, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(names))\n",
    "    plt.xticks(tick_marks, names, rotation=45)\n",
    "    plt.yticks(tick_marks, names)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "# Plot an ROC curve\n",
    "def plot_roc(pred, y):\n",
    "    fpr, tpr, thresholds = roc_curve(y, pred)\n",
    "    roc_area_under_curve = auc(fpr, tpr)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label='ROC curve (area = $0.2f)' % roc_area_under_curve)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC)')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show\n",
    " \n",
    "def text_to_word_list(text):\n",
    "    text = str(text)\n",
    "    text = text.lower()\n",
    "    \n",
    "    # clean text by regex\n",
    "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"cannot \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\",\", \" \", text)\n",
    "    text = re.sub(r\"\\.\", \" \", text)\n",
    "    text = re.sub(r\"!\", \" ! \", text)\n",
    "    text = re.sub(r\"\\/\", \" \", text)\n",
    "    text = re.sub(r\"\\^\", \" ^ \", text)\n",
    "    text = re.sub(r\"\\+\", \" + \", text)\n",
    "    text = re.sub(r\"\\-\", \" - \", text)\n",
    "    text = re.sub(r\"\\=\", \" = \", text)\n",
    "    text = re.sub(r\"\\'\", \" \", text)\n",
    "    text = re.sub(r\"'\", \" \", text)\n",
    "    text = re.sub(r\"(\\d+)(k)\", \"\\g<1>000\", text)\n",
    "    text = re.sub(r\":\", \" : \", text)\n",
    "    text = re.sub(r\" e g \", \" eg \", text)\n",
    "    text = re.sub(r\" b g \", \" bg \", text)\n",
    "    text = re.sub(r\" u s \", \" american \", text)\n",
    "    text = re.sub(r\"\\0s\", \"0\", text)\n",
    "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
    "    text = re.sub(r\"e - mail\", \"email\", text)\n",
    "    text = re.sub(r\"covid19\", \"covid\", text)\n",
    "    text = re.sub(r\"covid-19\", \"covid\", text)\n",
    "    text = re.sub(r\"covid - 19\", \"covid\", text)\n",
    "    text = re.sub(r\"j k\", \"jk\", text)\n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "    \n",
    "    text = text.split()\n",
    "    return text\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    stopwords_list = stopwords.words('english')\n",
    "    whitelist = [\"n't\", \"not\", \"no\"]\n",
    "    words = text.split()\n",
    "    words_clean = [word for word in words if (word not in stopwords_list or word in whitelist) and len(word) > 1]\n",
    "    return \" \".join(words_clean)\n",
    "    \n",
    "# Beep if on a windows machine\n",
    "if os.name == 'nt':\n",
    "    def ding():\n",
    "        winsound.Beep(2000, 300)\n",
    "        winsound.Beep(2000, 300)\n",
    "        winsound.Beep(2000, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deep_model(model, x_train, y_train, x_test, y_test):\n",
    "    model.compile(\n",
    "        optimizer='rmsprop',\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    history = model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        epochs=10,\n",
    "        batch_size=512,\n",
    "        validation_data=(x_test, y_test),\n",
    "        verbose=0\n",
    "    )\n",
    "    return history\n",
    "\n",
    "def eval_metric(history, metric_name):\n",
    "    metric = history.history[metric_name]\n",
    "    val_metric = history.history['val_' + metric_name]\n",
    "    e = range(1, 11)\n",
    "    \n",
    "    plt.plot(e, metric, 'bo', label=\"Train \" + metric_name)\n",
    "    plt.plot(e, val_metric, 'b', label=\"Validation \" + metric_name)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "def test_model(model, x_train, y_train, x_test, y_test, epoch):\n",
    "    model.fit(x_train, y_train, epochs=epoch, batch_size=512, verbose=0)\n",
    "    results = model.evaluate(x_test, y_test)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  title  \\\n",
      "0     Health Canada approves AstraZeneca COVID-19 va...   \n",
      "1     COVID-19 in Canada: 'Vaccination passports' a ...   \n",
      "2     Coronavirus variants could fuel Canada's third...   \n",
      "3     Canadian government to extend COVID-19 emergen...   \n",
      "4     Canada: Pfizer is 'extremely committed' to mee...   \n",
      "...                                                 ...   \n",
      "1486                                                      \n",
      "1487                                                      \n",
      "1488                                                      \n",
      "1489                                                      \n",
      "1490                                                      \n",
      "\n",
      "                                                   body  score  \n",
      "0                                                            7  \n",
      "1                                                            2  \n",
      "2                                                            6  \n",
      "3                                                            1  \n",
      "4                                                            6  \n",
      "...                                                 ...    ...  \n",
      "1486  The problem is the calculations themselves and...      0  \n",
      "1487  I created the Vaxfact site using references to...      1  \n",
      "1488  >The information I provided is not wrong\\n\\nYo...      1  \n",
      "1489  Basically nothing.\\n\\n>Autoimmunity to the cen...      1  \n",
      "1490  In this instance, yourself. Broader, that Vaxf...      0  \n",
      "\n",
      "[1491 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create pandas dataframe output file\n",
    "df_reddit = pd.read_csv('reddit_vm.csv', encoding=\"utf-8\")\n",
    "df_reddit = df_reddit[['title', 'body', 'score']].fillna('')\n",
    "df_reddit['title'] = df_reddit['title'].replace(to_replace='Comment', value='')\n",
    "\n",
    "print(df_reddit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  title  \\\n",
      "0     Health Canada approves AstraZeneca COVID-19 va...   \n",
      "1     COVID-19 in Canada: 'Vaccination passports' a ...   \n",
      "2     Coronavirus variants could fuel Canada's third...   \n",
      "3     Canadian government to extend COVID-19 emergen...   \n",
      "4     Canada: Pfizer is 'extremely committed' to mee...   \n",
      "...                                                 ...   \n",
      "1486                                                      \n",
      "1487                                                      \n",
      "1488                                                      \n",
      "1489                                                      \n",
      "1490                                                      \n",
      "\n",
      "                                                   body  score  \n",
      "0                                                            7  \n",
      "1                                                            2  \n",
      "2                                                            6  \n",
      "3                                                            1  \n",
      "4                                                            6  \n",
      "...                                                 ...    ...  \n",
      "1486  The problem calculations idea layperson napkin...      0  \n",
      "1487  created Vaxfact site using references reliable...      1  \n",
      "1488  >The information provided not wrong You've rep...      1  \n",
      "1489  Basically nothing. >Autoimmunity central nervo...      1  \n",
      "1490      In instance, yourself. Broader, Vaxfact site.      0  \n",
      "\n",
      "[1491 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "df_reddit.body = df_reddit.body.apply(remove_stopwords)\n",
    "print(df_reddit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'emb_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-171-cc80f77308fa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mcovid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'covid'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'virus'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'disease'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'sick'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'sickness'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'flu'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'vaccine'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcovid\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0memb_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Found {} in keys\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'emb_dict' is not defined"
     ]
    }
   ],
   "source": [
    "covid = ['covid', 'virus', 'disease', 'sick', 'sickness', 'flu', 'vaccine']\n",
    "for w in covid:\n",
    "    if w in emb_dict.keys():\n",
    "        print(\"Found {} in keys\".format(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Health Canada approves AstraZeneca COVID-19 va...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COVID-19 in Canada: 'Vaccination passports' a ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Coronavirus variants could fuel Canada's third...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Canadian government to extend COVID-19 emergen...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Canada: Pfizer is 'extremely committed' to mee...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1544</th>\n",
       "      <td>The problem calculations idea layperson napkin...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1545</th>\n",
       "      <td>created Vaxfact site using references reliable...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1546</th>\n",
       "      <td>&gt;The information provided not wrong You've rep...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1547</th>\n",
       "      <td>Basically nothing. &gt;Autoimmunity central nervo...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1548</th>\n",
       "      <td>In instance, yourself. Broader, Vaxfact site.</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1549 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  sentiment\n",
       "0     Health Canada approves AstraZeneca COVID-19 va...        0.0\n",
       "1     COVID-19 in Canada: 'Vaccination passports' a ...        0.0\n",
       "2     Coronavirus variants could fuel Canada's third...        0.0\n",
       "3     Canadian government to extend COVID-19 emergen...        0.0\n",
       "4     Canada: Pfizer is 'extremely committed' to mee...        0.0\n",
       "...                                                 ...        ...\n",
       "1544  The problem calculations idea layperson napkin...        0.0\n",
       "1545  created Vaxfact site using references reliable...        0.0\n",
       "1546  >The information provided not wrong You've rep...        0.0\n",
       "1547  Basically nothing. >Autoimmunity central nervo...        0.0\n",
       "1548      In instance, yourself. Broader, Vaxfact site.        0.0\n",
       "\n",
       "[1549 rows x 2 columns]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_title = df_reddit.title\n",
    "df_title.replace('', np.nan, inplace=True)\n",
    "df_body = df_reddit.body\n",
    "df_body.replace('', np.nan, inplace=True)\n",
    "df_title_clean = df_title.dropna().drop_duplicates().reset_index(drop=True)#.rename('title')\n",
    "df_body_clean = df_body.dropna().drop_duplicates().reset_index(drop=True)#.rename('title')\n",
    "\n",
    "df_corpus = pd.concat([df_title_clean, df_body_clean])\n",
    "df_dummy = pd.DataFrame(index=range(0, 1549), columns=['text', 'sentiment'], dtype='object')\n",
    "df_cor = df_corpus.to_frame(name='text')\n",
    "df_cor.reset_index(inplace=True)\n",
    "df_c = df_cor.drop('index', axis=1)\n",
    "df_dummy.text = df_c.text\n",
    "df_dummy.replace(np.nan, 0.0, inplace=True)\n",
    "df = df_dummy\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.text = df.text.apply(lambda x: text_to_word_list(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = df.copy()\n",
    "df_model = df_model[df_model.text.str.len() > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['health', 'canada', 'approves', 'astrazeneca', 'covid_vaccine']"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = [row for row in df_model.text]\n",
    "phrases = Phrases(sent, min_count=1, progress_per=50000)\n",
    "bigram = Phraser(phrases)\n",
    "sentences = bigram[sent]\n",
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to build vocab: 0.0 mins\n"
     ]
    }
   ],
   "source": [
    "w2v_model = Word2Vec(\n",
    "    min_count=3,\n",
    "    window=4,\n",
    "    vector_size=300,\n",
    "    sample=1e-5,\n",
    "    alpha=0.03,\n",
    "    min_alpha=0.0007,\n",
    "    negative=20,\n",
    "    workers=multiprocessing.cpu_count()-1\n",
    ")\n",
    "\n",
    "start = time.time()\n",
    "w2v_model.build_vocab(sentences, progress_per=50000)\n",
    "print('Time to build vocab: {} mins'.format(round((time.time() - start) / 60, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to build vocab: 0.02 mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\19165\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `init_sims` (Gensim 4.0.0 implemented internal optimizations that make calls to init_sims() unnecessary. init_sims() is now obsoleted and will be completely removed in future versions. See https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4).\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "w2v_model.train(sentences, total_examples=w2v_model.corpus_count, epochs=30, report_delay=1)\n",
    "print('Time to build vocab: {} mins'.format(round((time.time() - start) / 60, 2)))\n",
    "w2v_model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.save(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[health, canada, approves, astrazeneca, covid,...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[covid, in, canada, :, vaccination, passports,...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[coronavirus, variants, could, fuel, canada, t...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[canadian, government, to, extend, covid, emer...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[canada, :, pfizer, is, extremely, committed, ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1544</th>\n",
       "      <td>[the, problem, calculations, idea, layperson, ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1545</th>\n",
       "      <td>[created, vaxfact, site, using, references, re...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1546</th>\n",
       "      <td>[the, information, provided, not, wrong, you, ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1547</th>\n",
       "      <td>[basically, nothing, autoimmunity, central, ne...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1548</th>\n",
       "      <td>[in, instance, yourself, broader, vaxfact, site]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1508 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  sentiment\n",
       "0     [health, canada, approves, astrazeneca, covid,...        0.0\n",
       "1     [covid, in, canada, :, vaccination, passports,...        0.0\n",
       "2     [coronavirus, variants, could, fuel, canada, t...        0.0\n",
       "3     [canadian, government, to, extend, covid, emer...        0.0\n",
       "4     [canada, :, pfizer, is, extremely, committed, ...        0.0\n",
       "...                                                 ...        ...\n",
       "1544  [the, problem, calculations, idea, layperson, ...        0.0\n",
       "1545  [created, vaxfact, site, using, references, re...        0.0\n",
       "1546  [the, information, provided, not, wrong, you, ...        0.0\n",
       "1547  [basically, nothing, autoimmunity, central, ne...        0.0\n",
       "1548   [in, instance, yourself, broader, vaxfact, site]        0.0\n",
       "\n",
       "[1508 rows x 2 columns]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_export = df_model.copy()\n",
    "df_export['old_text'] = df_export.text\n",
    "df_export.old_text = df_export.old_text.str.join(' ')\n",
    "df_export.text = df_export.text.apply(lambda x: ' '.join(bigram[x]))\n",
    "df_export.sentiment = df_export.sentiment.astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_export[['text', 'sentiment']].to_csv('cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
